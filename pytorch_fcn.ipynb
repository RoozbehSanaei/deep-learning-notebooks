{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python [conda env:py36]",
      "language": "python",
      "name": "conda-env-py36-py"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.4"
    },
    "colab": {
      "name": "pytorch_fcn.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/RoozbehSanaei/deep-learning-notebooks/blob/master/pytorch_fcn.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LTTaaiEGO-p_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import numpy as np\n",
        "import random\n",
        "\n",
        "def generate_random_data(height, width, count):\n",
        "    x, y = zip(*[generate_img_and_mask(height, width) for i in range(0, count)])\n",
        "\n",
        "    X = np.asarray(x) * 255\n",
        "    X = X.repeat(3, axis=1).transpose([0, 2, 3, 1]).astype(np.uint8)\n",
        "    Y = np.asarray(y)\n",
        "\n",
        "    return X, Y\n",
        "\n",
        "def generate_img_and_mask(height, width):\n",
        "    shape = (height, width)\n",
        "\n",
        "    triangle_location = get_random_location(*shape)\n",
        "    circle_location1 = get_random_location(*shape, zoom=0.7)\n",
        "    circle_location2 = get_random_location(*shape, zoom=0.5)\n",
        "    mesh_location = get_random_location(*shape)\n",
        "    square_location = get_random_location(*shape, zoom=0.8)\n",
        "    plus_location = get_random_location(*shape, zoom=1.2)\n",
        "\n",
        "    # Create input image\n",
        "    arr = np.zeros(shape, dtype=bool)\n",
        "    arr = add_triangle(arr, *triangle_location)\n",
        "    arr = add_circle(arr, *circle_location1)\n",
        "    arr = add_circle(arr, *circle_location2, fill=True)\n",
        "    arr = add_mesh_square(arr, *mesh_location)\n",
        "    arr = add_filled_square(arr, *square_location)\n",
        "    arr = add_plus(arr, *plus_location)\n",
        "    arr = np.reshape(arr, (1, height, width)).astype(np.float32)\n",
        "\n",
        "    # Create target masks\n",
        "    masks = np.asarray([\n",
        "        add_filled_square(np.zeros(shape, dtype=bool), *square_location),\n",
        "        add_circle(np.zeros(shape, dtype=bool), *circle_location2, fill=True),\n",
        "        add_triangle(np.zeros(shape, dtype=bool), *triangle_location),\n",
        "        add_circle(np.zeros(shape, dtype=bool), *circle_location1),\n",
        "         add_filled_square(np.zeros(shape, dtype=bool), *mesh_location),\n",
        "        # add_mesh_square(np.zeros(shape, dtype=bool), *mesh_location),\n",
        "        add_plus(np.zeros(shape, dtype=bool), *plus_location)\n",
        "    ]).astype(np.float32)\n",
        "\n",
        "    return arr, masks\n",
        "\n",
        "def add_square(arr, x, y, size):\n",
        "    s = int(size / 2)\n",
        "    arr[x-s,y-s:y+s] = True\n",
        "    arr[x+s,y-s:y+s] = True\n",
        "    arr[x-s:x+s,y-s] = True\n",
        "    arr[x-s:x+s,y+s] = True\n",
        "\n",
        "    return arr\n",
        "\n",
        "def add_filled_square(arr, x, y, size):\n",
        "    s = int(size / 2)\n",
        "\n",
        "    xx, yy = np.mgrid[:arr.shape[0], :arr.shape[1]]\n",
        "\n",
        "    return np.logical_or(arr, logical_and([xx > x - s, xx < x + s, yy > y - s, yy < y + s]))\n",
        "\n",
        "def logical_and(arrays):\n",
        "    new_array = np.ones(arrays[0].shape, dtype=bool)\n",
        "    for a in arrays:\n",
        "        new_array = np.logical_and(new_array, a)\n",
        "\n",
        "    return new_array\n",
        "\n",
        "def add_mesh_square(arr, x, y, size):\n",
        "    s = int(size / 2)\n",
        "\n",
        "    xx, yy = np.mgrid[:arr.shape[0], :arr.shape[1]]\n",
        "\n",
        "    return np.logical_or(arr, logical_and([xx > x - s, xx < x + s, xx % 2 == 1, yy > y - s, yy < y + s, yy % 2 == 1]))\n",
        "\n",
        "def add_triangle(arr, x, y, size):\n",
        "    s = int(size / 2)\n",
        "\n",
        "    triangle = np.tril(np.ones((size, size), dtype=bool))\n",
        "\n",
        "    arr[x-s:x-s+triangle.shape[0],y-s:y-s+triangle.shape[1]] = triangle\n",
        "\n",
        "    return arr\n",
        "\n",
        "def add_circle(arr, x, y, size, fill=False):\n",
        "    xx, yy = np.mgrid[:arr.shape[0], :arr.shape[1]]\n",
        "    circle = np.sqrt((xx - x) ** 2 + (yy - y) ** 2)\n",
        "    new_arr = np.logical_or(arr, np.logical_and(circle < size, circle >= size * 0.7 if not fill else True))\n",
        "\n",
        "    return new_arr\n",
        "\n",
        "def add_plus(arr, x, y, size):\n",
        "    s = int(size / 2)\n",
        "    arr[x-1:x+1,y-s:y+s] = True\n",
        "    arr[x-s:x+s,y-1:y+1] = True\n",
        "\n",
        "    return arr\n",
        "\n",
        "def get_random_location(width, height, zoom=1.0):\n",
        "    x = int(width * random.uniform(0.1, 0.9))\n",
        "    y = int(height * random.uniform(0.1, 0.9))\n",
        "\n",
        "    size = int(min(width, height) * random.uniform(0.06, 0.12) * zoom)\n",
        "\n",
        "    return (x, y, size)\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "\n",
        "def plot_img_array(img_array, ncol=3):\n",
        "    nrow = len(img_array) // ncol\n",
        "\n",
        "    f, plots = plt.subplots(nrow, ncol, sharex='all', sharey='all', figsize=(ncol * 4, nrow * 4))\n",
        "\n",
        "    for i in range(len(img_array)):\n",
        "        plots[i // ncol, i % ncol]\n",
        "        plots[i // ncol, i % ncol].imshow(img_array[i])\n",
        "\n",
        "from functools import reduce\n",
        "def plot_side_by_side(img_arrays):\n",
        "    flatten_list = reduce(lambda x,y: x+y, zip(*img_arrays))\n",
        "\n",
        "    plot_img_array(np.array(flatten_list), ncol=len(img_arrays))\n",
        "\n",
        "import itertools\n",
        "def plot_errors(results_dict, title):\n",
        "    markers = itertools.cycle(('+', 'x', 'o'))\n",
        "\n",
        "    plt.title('{}'.format(title))\n",
        "\n",
        "    for label, result in sorted(results_dict.items()):\n",
        "        plt.plot(result, marker=next(markers), label=label)\n",
        "        plt.ylabel('dice_coef')\n",
        "        plt.xlabel('epoch')\n",
        "        plt.legend(loc=3, bbox_to_anchor=(1, 0))\n",
        "\n",
        "    plt.show()\n",
        "\n",
        "def masks_to_colorimg(masks):\n",
        "    colors = np.asarray([(201, 58, 64), (242, 207, 1), (0, 152, 75), (101, 172, 228),(56, 34, 132), (160, 194, 56)])\n",
        "\n",
        "    colorimg = np.ones((masks.shape[1], masks.shape[2], 3), dtype=np.float32) * 255\n",
        "    channels, height, width = masks.shape\n",
        "\n",
        "    for y in range(height):\n",
        "        for x in range(width):\n",
        "            selected_colors = colors[masks[:,y,x] > 0.5]\n",
        "\n",
        "            if len(selected_colors) > 0:\n",
        "                colorimg[y,x,:] = np.mean(selected_colors, axis=0)\n",
        "\n",
        "    return colorimg.astype(np.uint8)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "s8WBWN2gniNf",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QM3tWTETRAIN",
        "colab_type": "code",
        "outputId": "a0351d55-6b75-4122-8764-18eb8019787b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 806
        }
      },
      "source": [
        "%matplotlib inline\n",
        "%load_ext autoreload\n",
        "%autoreload 2\n",
        "\n",
        "import os,sys\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import helper\n",
        "\n",
        "# Generate some random images\n",
        "input_images, target_masks = generate_random_data(192, 192, count=3)\n",
        "\n",
        "for x in [input_images, target_masks]:\n",
        "    print(x.shape)\n",
        "    print(x.min(), x.max())\n",
        "\n",
        "# Change channel-order and make 3 channels for matplot\n",
        "input_images_rgb = [x.astype(np.uint8) for x in input_images]\n",
        "\n",
        "# Map each channel (i.e. class) to each color\n",
        "target_masks_rgb = [masks_to_colorimg(x) for x in target_masks]\n",
        "\n",
        "# Left: Input image, Right: Target mask (Ground-truth)\n",
        "plot_side_by_side([input_images_rgb, target_masks_rgb])"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "The autoreload extension is already loaded. To reload it, use:\n",
            "  %reload_ext autoreload\n",
            "(3, 192, 192, 3)\n",
            "0 255\n",
            "(3, 6, 192, 192)\n",
            "0.0 1.0\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAdsAAAKvCAYAAAAiIWV+AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
            "text/plain": [
              "<Figure size 576x864 with 6 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "L4hLmb5NO-qG",
        "colab_type": "code",
        "outputId": "f45c4157-13dc-4891-dc67-7475e3af45d0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "from torchvision import models\n",
        "\n",
        "base_model = models.resnet18(pretrained=True)\n",
        "\n",
        "def find_last_layer(layer):\n",
        "    children = list(layer.children())\n",
        "    if len(children) == 0:\n",
        "        return layer\n",
        "    else:\n",
        "        return find_last_layer(children[-1])\n",
        "    \n",
        "list(base_model.children())"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading: \"https://download.pytorch.org/models/resnet18-5c106cde.pth\" to /root/.cache/torch/checkpoints/resnet18-5c106cde.pth\n",
            "100%|██████████| 44.7M/44.7M [00:01<00:00, 28.4MB/s]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False),\n",
              " BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True),\n",
              " ReLU(inplace=True),\n",
              " MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False),\n",
              " Sequential(\n",
              "   (0): BasicBlock(\n",
              "     (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "     (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "     (relu): ReLU(inplace=True)\n",
              "     (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "     (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "   )\n",
              "   (1): BasicBlock(\n",
              "     (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "     (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "     (relu): ReLU(inplace=True)\n",
              "     (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "     (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "   )\n",
              " ),\n",
              " Sequential(\n",
              "   (0): BasicBlock(\n",
              "     (conv1): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
              "     (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "     (relu): ReLU(inplace=True)\n",
              "     (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "     (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "     (downsample): Sequential(\n",
              "       (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
              "       (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "     )\n",
              "   )\n",
              "   (1): BasicBlock(\n",
              "     (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "     (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "     (relu): ReLU(inplace=True)\n",
              "     (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "     (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "   )\n",
              " ),\n",
              " Sequential(\n",
              "   (0): BasicBlock(\n",
              "     (conv1): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
              "     (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "     (relu): ReLU(inplace=True)\n",
              "     (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "     (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "     (downsample): Sequential(\n",
              "       (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
              "       (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "     )\n",
              "   )\n",
              "   (1): BasicBlock(\n",
              "     (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "     (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "     (relu): ReLU(inplace=True)\n",
              "     (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "     (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "   )\n",
              " ),\n",
              " Sequential(\n",
              "   (0): BasicBlock(\n",
              "     (conv1): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
              "     (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "     (relu): ReLU(inplace=True)\n",
              "     (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "     (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "     (downsample): Sequential(\n",
              "       (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
              "       (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "     )\n",
              "   )\n",
              "   (1): BasicBlock(\n",
              "     (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "     (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "     (relu): ReLU(inplace=True)\n",
              "     (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "     (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "   )\n",
              " ),\n",
              " AdaptiveAvgPool2d(output_size=(1, 1)),\n",
              " Linear(in_features=512, out_features=1000, bias=True)]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-8-LC-6cO-qJ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from torch import nn\n",
        "\n",
        "model_wo_avgpool = nn.Sequential(*list(base_model.children())[:-2])\n",
        "\n",
        "#OrderedDict(model_wo_avgpool.named_children())"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IdTfmoVoO-qM",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import torch\n",
        "\n",
        "class FCN(nn.Module):\n",
        "\n",
        "    def __init__(self, n_class):\n",
        "        super().__init__()\n",
        "        \n",
        "        self.base_model = models.resnet18(pretrained=True)\n",
        "        \n",
        "        layers = list(base_model.children())\n",
        "        self.layer1 = nn.Sequential(*layers[:5]) # size=(N, 64, x.H/2, x.W/2)\n",
        "        self.upsample1 = nn.Upsample(scale_factor=4, mode='bilinear')\n",
        "        self.layer2 = layers[5]  # size=(N, 128, x.H/4, x.W/4)\n",
        "        self.upsample2 = nn.Upsample(scale_factor=8, mode='bilinear')\n",
        "        self.layer3 = layers[6]  # size=(N, 256, x.H/8, x.W/8)\n",
        "        self.upsample3 = nn.Upsample(scale_factor=16, mode='bilinear')\n",
        "        self.layer4 = layers[7]  # size=(N, 512, x.H/16, x.W/16)\n",
        "        self.upsample4 = nn.Upsample(scale_factor=32, mode='bilinear')\n",
        "        \n",
        "        self.conv1k = nn.Conv2d(64 + 128 + 256 + 512, n_class, 1)\n",
        "        self.sigmoid = nn.Sigmoid()\n",
        "        \n",
        "    def forward(self, x):\n",
        "        x = self.layer1(x)\n",
        "        up1 = self.upsample1(x)\n",
        "        x = self.layer2(x)\n",
        "        up2 = self.upsample2(x)\n",
        "        x = self.layer3(x)\n",
        "        up3 = self.upsample3(x)\n",
        "        x = self.layer4(x)\n",
        "        up4 = self.upsample4(x)\n",
        "        \n",
        "        merge = torch.cat([up1, up2, up3, up4], dim=1)\n",
        "        merge = self.conv1k(merge)\n",
        "        out = self.sigmoid(merge)\n",
        "        \n",
        "        return out\n",
        "\n",
        "fcn_model = FCN(6)\n",
        "\n",
        "import torchsummary\n",
        "\n",
        "#torchsummary.summary(fcn_model, input_size=(3, 224, 224), device='cpu')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7TvNuOhZO-qP",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def train_model(model, criterion, optimizer, scheduler, num_epochs=25):\n",
        "    since = time.time()\n",
        "\n",
        "    best_model_wts = copy.deepcopy(model.state_dict())\n",
        "    best_loss = 1e10\n",
        "\n",
        "    for epoch in range(num_epochs):\n",
        "        print('Epoch {}/{}'.format(epoch, num_epochs - 1))\n",
        "        print('-' * 10)\n",
        "\n",
        "        # Each epoch has a training and validation phase\n",
        "        for phase in ['train', 'val']:\n",
        "            if phase == 'train':\n",
        "                scheduler.step()\n",
        "                model.train()  # Set model to training mode\n",
        "            else:\n",
        "                model.eval()   # Set model to evaluate mode\n",
        "\n",
        "            running_loss = 0.0\n",
        "            running_corrects = 0\n",
        "\n",
        "            # Iterate over data.\n",
        "            batch_size = 10\n",
        "            epoch_steps = 10\n",
        "            for i in range(epoch_steps):\n",
        "                input_images, target_masks = generate_random_data(192, 192, count=batch_size)\n",
        "\n",
        "                inputs = torch.from_numpy(input_images)\n",
        "                labels = torch.from_numpy(target_masks)\n",
        "                inputs = inputs.to(device)\n",
        "                labels = labels.to(device)                \n",
        "\n",
        "                # zero the parameter gradients\n",
        "                optimizer.zero_grad()\n",
        "\n",
        "                # forward\n",
        "                # track history if only in train\n",
        "                with torch.set_grad_enabled(phase == 'train'):\n",
        "                    outputs = model(inputs)\n",
        "                    loss = criterion(outputs, labels)\n",
        "\n",
        "                    # backward + optimize only if in training phase\n",
        "                    if phase == 'train':\n",
        "                        loss.backward()\n",
        "                        optimizer.step()\n",
        "\n",
        "                # statistics\n",
        "                running_loss += loss.item() * inputs.size(0)\n",
        "\n",
        "            epoch_loss = running_loss / (batch_size * epoch_steps)\n",
        "\n",
        "            print('{} Loss: {:.4f}'.format(\n",
        "                phase, epoch_loss))\n",
        "\n",
        "            # deep copy the model\n",
        "            if phase == 'val' and epoch_loss < best_loss:\n",
        "                best_loss = epoch_loss\n",
        "                best_model_wts = copy.deepcopy(model.state_dict())\n",
        "\n",
        "        print()\n",
        "\n",
        "    time_elapsed = time.time() - since\n",
        "    print('Training complete in {:.0f}m {:.0f}s'.format(\n",
        "        time_elapsed // 60, time_elapsed % 60))\n",
        "    print('Best val loss: {:4f}'.format(best_loss))\n",
        "\n",
        "    # load best model weights\n",
        "    model.load_state_dict(best_model_wts)\n",
        "    return model"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "z6Pvgw-KO-qT",
        "colab_type": "code",
        "outputId": "21171c10-02ec-499a-bf6c-fd3795c60cbf",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 428
        }
      },
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.optim import lr_scheduler\n",
        "import time\n",
        "import copy\n",
        "\n",
        "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "model_ft = FCN(6).to(device)\n",
        "\n",
        "criterion = nn.BCELoss()\n",
        "\n",
        "# Observe that all parameters are being optimized\n",
        "optimizer_ft = optim.SGD(model_ft.parameters(), lr=0.001, momentum=0.9)\n",
        "\n",
        "# Decay LR by a factor of 0.1 every 7 epochs\n",
        "exp_lr_scheduler = lr_scheduler.StepLR(optimizer_ft, step_size=7, gamma=0.1)\n",
        "\n",
        "model_ft = train_model(model_ft, criterion, optimizer_ft, exp_lr_scheduler, num_epochs=25)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 0/24\n",
            "----------\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/torch/optim/lr_scheduler.py:100: UserWarning: Detected call of `lr_scheduler.step()` before `optimizer.step()`. In PyTorch 1.1.0 and later, you should call them in the opposite order: `optimizer.step()` before `lr_scheduler.step()`.  Failure to do this will result in PyTorch skipping the first value of the learning rate schedule.See more details at https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate\n",
            "  \"https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate\", UserWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "error",
          "ename": "RuntimeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-25-11cebe421388>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     18\u001b[0m \u001b[0mexp_lr_scheduler\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlr_scheduler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mStepLR\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moptimizer_ft\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstep_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m7\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgamma\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 20\u001b[0;31m \u001b[0mmodel_ft\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel_ft\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer_ft\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexp_lr_scheduler\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_epochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m25\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-23-318a0540313b>\u001b[0m in \u001b[0;36mtrain_model\u001b[0;34m(model, criterion, optimizer, scheduler, num_epochs)\u001b[0m\n\u001b[1;32m     37\u001b[0m                 \u001b[0;31m# track history if only in train\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     38\u001b[0m                 \u001b[0;32mwith\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_grad_enabled\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mphase\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'train'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 39\u001b[0;31m                     \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     40\u001b[0m                     \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     41\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    539\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    540\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 541\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    542\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    543\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-16-c928d1617b63>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     22\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 24\u001b[0;31m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayer1\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     25\u001b[0m         \u001b[0mup1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupsample1\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     26\u001b[0m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayer2\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    539\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    540\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 541\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    542\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    543\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/nn/modules/container.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m     90\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     91\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mmodule\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_modules\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 92\u001b[0;31m             \u001b[0minput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodule\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     93\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     94\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    539\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    540\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 541\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    542\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    543\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/nn/modules/conv.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    343\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    344\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 345\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconv2d_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    346\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    347\u001b[0m \u001b[0;32mclass\u001b[0m \u001b[0mConv3d\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_ConvNd\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/nn/modules/conv.py\u001b[0m in \u001b[0;36mconv2d_forward\u001b[0;34m(self, input, weight)\u001b[0m\n\u001b[1;32m    340\u001b[0m                             _pair(0), self.dilation, self.groups)\n\u001b[1;32m    341\u001b[0m         return F.conv2d(input, weight, self.bias, self.stride,\n\u001b[0;32m--> 342\u001b[0;31m                         self.padding, self.dilation, self.groups)\n\u001b[0m\u001b[1;32m    343\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    344\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mRuntimeError\u001b[0m: Given groups=1, weight of size 64 3 7 7, expected input[10, 192, 192, 3] to have 3 channels, but got 192 channels instead"
          ]
        }
      ]
    }
  ]
}