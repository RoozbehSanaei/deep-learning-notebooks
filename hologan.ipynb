{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "HoloGAN.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyMWutyXKGgHuLEUby/5WFRw",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/RoozbehSanaei/deep-learning-notebooks/blob/master/hologan.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Zdo2MuZt6Ohi",
        "colab_type": "code",
        "cellView": "form",
        "outputId": "78d7a7d8-bac7-4157-81a3-b8254d0f773a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 50
        }
      },
      "source": [
        "#@title Utilities\n",
        "!git clone https://github.com/dimatura/binvox-rw-py\n",
        "print(\"*\")\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "import tensorflow.contrib as tf_contrib\n",
        "import tensorflow.contrib.slim as slim\n",
        "import os\n",
        "# from tools.ops import *\n",
        "import math\n",
        "import glob\n",
        "import scipy.io\n",
        "import time\n",
        "from __future__ import division\n",
        "import tarfile\n",
        "import zlib\n",
        "import io\n",
        "from PIL import Image\n",
        "import pprint\n",
        "import random\n",
        "import scipy.misc\n",
        "import sys\n",
        "import glob\n",
        "sys.path.insert(1, 'binvox-rw-py/')\n",
        "import binvox_rw\n",
        "\n",
        "def get_weight(weight_name, weight_dict):\n",
        "    if weight_dict is None:\n",
        "        return None\n",
        "    else:\n",
        "        return weight_dict.get(weight_name)  # returns None if name is not found in dictionary\n",
        "\n",
        "def res_block_3d(input, out_channels=64, scope = 'res_block', kernel=[3, 3, 3], prob = 0.5,  stride=[1, 1, 1], weight_dict=None):\n",
        "    with tf.variable_scope(scope):\n",
        "        net = tf.nn.relu(conv3d(input, out_channels, kernel_size=kernel, stride=stride, pad=\"SAME\", scope=\"con1_3X3\",\n",
        "                                weight_initializer=get_weight(scope + 'con1_3X3_weights', weight_dict),\n",
        "                                bias_initializer=get_weight(scope + 'con1_3X3_biases', weight_dict),\n",
        "                                weight_initializer_type=tf.contrib.layers.xavier_initializer()))\n",
        "        # net = tf.nn.dropout(net, keep_prob(prob, is_training))\n",
        "        net = conv3d(net, out_channels, kernel_size=kernel, stride=stride, pad=\"SAME\", scope=\"conv2_3x3\",\n",
        "                     weight_initializer=get_weight(scope + 'conv2_3x3_weights', weight_dict),\n",
        "                     bias_initializer=get_weight(scope + 'conv2_3x3_biases', weight_dict),\n",
        "                     weight_initializer_type=tf.contrib.layers.xavier_initializer())\n",
        "        # net = tf.nn.dropout(net, keep_prob(prob, is_training))\n",
        "    return tf.add(tf.cast(net, tf.float32), tf.cast(input, tf.float32))\n",
        "\n",
        "\n",
        "def res_block_2d(input, out_channels=64, scope = 'res_block', kernel=[3, 3], prob = 0.5,  stride=[1, 1], weight_dict=None):\n",
        "    with tf.variable_scope(scope):\n",
        "        net = tf.nn.relu(conv2d(input, out_channels, kernel_size=kernel, stride=stride, pad=\"SAME\", scope=\"con1_3X3\",\n",
        "                                weight_initializer=get_weight(scope + 'con1_3X3_weights', weight_dict),\n",
        "                                bias_initializer=get_weight(scope + 'con1_3X3_biases', weight_dict),\n",
        "                                weight_initializer_type=tf.contrib.layers.xavier_initializer()))\n",
        "        # net = tf.nn.dropout(net, keep_prob(prob, is_training))\n",
        "        net = conv2d(net, out_channels, kernel_size=kernel, stride=stride, pad=\"SAME\", scope=\"conv2_3x3\",\n",
        "                     weight_initializer=get_weight(scope + 'conv2_3x3_weights', weight_dict),\n",
        "                     bias_initializer=get_weight(scope + 'conv2_3x3_biases', weight_dict),\n",
        "                     weight_initializer_type=tf.contrib.layers.xavier_initializer())\n",
        "        # net = tf.nn.dropout(net, keep_prob(prob, is_training))\n",
        "    return tf.add(tf.cast(net, tf.float32), tf.cast(input, tf.float32))\n",
        "\n",
        "\n",
        "def bias_variable(shape, bias_initializer=None, trainable=True):\n",
        "    if bias_initializer is None :\n",
        "        return tf.get_variable(name='biases', initializer=tf.constant(0.0, shape=shape), trainable = trainable)\n",
        "    else:\n",
        "        return tf.get_variable(name='biases', initializer=bias_initializer, trainable = trainable)\n",
        "\n",
        "\n",
        "def _conv_init_vars(net, out_channels, filter_size, transpose=False):\n",
        "    _, rows, cols, in_channels = [i.value for i in net.get_shape()]\n",
        "    if not transpose:\n",
        "        weights_shape = [filter_size, filter_size, in_channels, out_channels]\n",
        "    else:\n",
        "        weights_shape = [filter_size, filter_size, out_channels, in_channels]\n",
        "\n",
        "    weights_init = tf.Variable(tf.truncated_normal(weights_shape, stddev=0.1, seed=1), dtype=tf.float32)\n",
        "    return weights_init\n",
        "\n",
        "def conv2d(input_, num_outputs, kernel_size=[4,4], stride=[1,1], pad='SAME', if_bias=True, trainable=True, reuse=False,\n",
        "           scope='conv2d', weight_initializer=None, bias_initializer=None,\n",
        "           weight_initializer_type=tf.random_normal_initializer(stddev=0.02)):\n",
        "    print(scope)\n",
        "    with tf.variable_scope(scope, reuse = reuse):\n",
        "        if weight_initializer is None:\n",
        "            print(\"Initializing weights\")\n",
        "            w = tf.get_variable(name='weights',\n",
        "                                shape = kernel_size +  [input_.get_shape()[-1]] + [num_outputs],\n",
        "                                initializer = weight_initializer_type,\n",
        "                                dtype = tf.float32, trainable=trainable)\n",
        "        else:\n",
        "            print(\"Loading weights\")\n",
        "            w = tf.get_variable(name='weights',\n",
        "                                initializer = weight_initializer,\n",
        "                                dtype = tf.float32, trainable=trainable)\n",
        "\n",
        "        conv = tf.nn.conv2d(input_, w,\n",
        "                            padding = pad,\n",
        "                            strides = [1] + stride + [1])\n",
        "\n",
        "        if if_bias:\n",
        "            if bias_initializer is None:\n",
        "                print(\"Initializing biases\")\n",
        "                conv=conv+bias_variable([num_outputs], trainable=trainable)\n",
        "            else:\n",
        "                print(\"Loading biases\")\n",
        "                conv=conv+bias_variable([num_outputs], trainable=trainable, bias_initializer=bias_initializer)\n",
        "\n",
        "        return conv\n",
        "\n",
        "\n",
        "def conv2d_transpose(x, num_outputs, kernel_size = (4,4), stride= (1,1), pad='SAME', if_bias=True,\n",
        "                     reuse=False, scope = \"conv2d_transpose\", trainable = True, weight_initializer=None,\n",
        "                     bias_initializer=None, weight_initializer_type=tf.random_normal_initializer(stddev=0.02)):\n",
        "    print(scope)\n",
        "    with tf.variable_scope(scope, reuse = reuse):\n",
        "        if weight_initializer is None:\n",
        "            print(\"Initializing weights\")\n",
        "            w = tf.get_variable(name='weights',\n",
        "                                shape = kernel_size + [num_outputs] + [x.get_shape()[-1]],\n",
        "                                initializer=weight_initializer_type,\n",
        "                                dtype = tf.float32, trainable=trainable)\n",
        "        else:\n",
        "            print(\"Loading weights\")\n",
        "            w = tf.get_variable(name='weights',\n",
        "                                initializer=weight_initializer,\n",
        "                                dtype = tf.float32, trainable=trainable)\n",
        "\n",
        "        output_shape = [tf.shape(x)[0], tf.shape(x)[1] * stride[0], tf.shape(x)[2] * stride[1], num_outputs]\n",
        "\n",
        "        conv_trans = tf.nn.conv2d_transpose(x, w,\n",
        "                                            output_shape = output_shape,\n",
        "                                            strides = [1] + stride + [1],\n",
        "                                            padding = pad)\n",
        "\n",
        "        if if_bias:\n",
        "            if bias_initializer is None:\n",
        "                print(\"Initializing biases\")\n",
        "                conv_trans = conv_trans + bias_variable([num_outputs], trainable=trainable)\n",
        "            else:\n",
        "                print(\"Load biases\")\n",
        "                conv_trans = conv_trans + bias_variable([num_outputs], trainable=trainable, bias_initializer=bias_initializer)\n",
        "\n",
        "\n",
        "        return conv_trans\n",
        "\n",
        "def conv2d_specnorm(input_, num_outputs, kernel_size=[4,4], stride=[1,1], pad='SAME', if_bias=True, trainable=True, reuse=False,\n",
        "           scope='conv2d', weight_initializer=None, bias_initializer=None, u_weight=None,\n",
        "           weight_initializer_type=tf.random_normal_initializer(stddev=0.02)):\n",
        "    print(scope)\n",
        "    with tf.variable_scope(scope, reuse = reuse):\n",
        "        if weight_initializer is None:\n",
        "            print(\"Initializing weights\")\n",
        "            w = tf.get_variable(name='weights',\n",
        "                                shape = kernel_size +  [input_.get_shape()[-1]] + [num_outputs],\n",
        "                                initializer = weight_initializer_type,\n",
        "                                dtype = tf.float32, trainable=trainable)\n",
        "        else:\n",
        "            print(\"Loading weights\")\n",
        "            w = tf.get_variable(name='weights',\n",
        "                                initializer = weight_initializer,\n",
        "                                dtype = tf.float32, trainable=trainable)\n",
        "\n",
        "        conv = tf.nn.conv2d(input_, spectral_norm(w, 1, u_weight=u_weight),\n",
        "                            padding = pad,\n",
        "                            strides = [1] + stride + [1])\n",
        "\n",
        "        if if_bias:\n",
        "            if bias_initializer is None:\n",
        "                print(\"Initializing biases\")\n",
        "                conv=conv+bias_variable([num_outputs], trainable=trainable)\n",
        "            else:\n",
        "                print(\"Loading biases\")\n",
        "                conv=conv+bias_variable([num_outputs], trainable=trainable, bias_initializer=bias_initializer)\n",
        "\n",
        "        return conv\n",
        "\n",
        "def conv2d_transpose_specNorm(x, num_outputs, kernel_size = (4,4), stride= (1,1), pad='SAME', if_bias=True,\n",
        "                     reuse=False, scope = \"conv2d_transpose\", trainable = True, weight_initializer=None,\n",
        "                     bias_initializer=None, u_weight=None, weight_initializer_type=tf.random_normal_initializer(stddev=0.02)):\n",
        "    print(scope)\n",
        "    with tf.variable_scope(scope, reuse = reuse):\n",
        "        if weight_initializer is None:\n",
        "            print(\"Initializing weights\")\n",
        "            w = tf.get_variable(name='weights',\n",
        "                                shape = kernel_size + [num_outputs] + [x.get_shape()[-1]],\n",
        "                                initializer=weight_initializer_type,\n",
        "                                dtype = tf.float32, trainable=trainable)\n",
        "        else:\n",
        "            print(\"Loading weights\")\n",
        "            w = tf.get_variable(name='weights',\n",
        "                                initializer=weight_initializer,\n",
        "                                dtype = tf.float32, trainable=trainable)\n",
        "\n",
        "        output_shape = [tf.shape(x)[0], tf.shape(x)[1] * stride[0], tf.shape(x)[2] * stride[1], num_outputs]\n",
        "\n",
        "        conv_trans = tf.nn.conv2d_transpose(x, spectral_norm(w, 1, u_weight),\n",
        "                                            output_shape = output_shape,\n",
        "                                            strides = [1] + stride + [1],\n",
        "                                            padding = pad)\n",
        "\n",
        "        if if_bias:\n",
        "            if bias_initializer is None:\n",
        "                print(\"Initializing biases\")\n",
        "                conv_trans = conv_trans + bias_variable([num_outputs], trainable=trainable)\n",
        "            else:\n",
        "                print(\"Load biases\")\n",
        "                conv_trans = conv_trans + bias_variable([num_outputs], trainable=trainable, bias_initializer=bias_initializer)\n",
        "\n",
        "\n",
        "        return conv_trans\n",
        "\n",
        "def conv3d(input_, num_outputs, pad = \"SAME\", reuse = False, kernel_size = [4,4,4], stride = [2,2,2], if_bias= True,\n",
        "           trainable = True, scope = \"conv3d\", weight_initializer=None, bias_initializer=None, weight_initializer_type = tf.random_normal_initializer(stddev=0.02)):\n",
        "    print(scope)\n",
        "    with tf.variable_scope(scope, reuse = reuse):\n",
        "        if weight_initializer is None:\n",
        "            print(\"Initialise weight\")\n",
        "            w = tf.get_variable(name='weights',\n",
        "                                trainable=trainable,\n",
        "                                shape=kernel_size + [input_.get_shape()[-1]] + [num_outputs],\n",
        "                                initializer=weight_initializer_type,\n",
        "                                dtype=tf.float32)\n",
        "        else:\n",
        "            print(\"Loading weight\")\n",
        "            w = tf.get_variable(name='weights',\n",
        "                                trainable=trainable,\n",
        "                                initializer=weight_initializer,\n",
        "                                dtype=tf.float32)\n",
        "\n",
        "        conv = tf.nn.conv3d(input_, w,\n",
        "                            padding = pad,\n",
        "                            strides = [1] + stride + [1])\n",
        "\n",
        "        if if_bias:\n",
        "            if bias_initializer is None:\n",
        "                print(\"Initialise bias\")\n",
        "                conv = conv + bias_variable([num_outputs], trainable=trainable)\n",
        "            else:\n",
        "                print(\"Loading bias\")\n",
        "                conv = conv + bias_variable([num_outputs], trainable=trainable, bias_initializer=bias_initializer)\n",
        "\n",
        "        return conv\n",
        "\n",
        "\n",
        "\n",
        "def conv3d_transpose(x, num_output, kernel_size = (4,4), stride= (1,1), pad='SAME', if_bias=True,\n",
        "                     reuse=False, scope = \"conv3d_transpose\", trainable = True, weight_initializer=None,\n",
        "                     bias_initializer=None, weight_initializer_type=tf.random_normal_initializer(stddev=0.02)):\n",
        "\n",
        "    print(scope)\n",
        "    with tf.variable_scope(scope, reuse = reuse):\n",
        "        if weight_initializer is None:\n",
        "            print(\"Initializing weights\")\n",
        "            w = tf.get_variable(name='weights',\n",
        "                                shape = kernel_size + [num_output] + [x.get_shape().as_list()[-1]],\n",
        "                                initializer=weight_initializer_type,\n",
        "                                dtype = tf.float32, trainable=trainable)\n",
        "        else:\n",
        "            print(\"Loading weights\")\n",
        "            w = tf.get_variable(name='weights',\n",
        "                                initializer=weight_initializer,\n",
        "                                dtype = tf.float32, trainable=trainable)\n",
        "        print(\"W \" + str(w.get_shape()))\n",
        "        output_shape = [tf.shape(x)[0], tf.shape(x)[1] * stride[0], tf.shape(x)[2] * stride[1], tf.shape(x)[3] * stride[2], num_output]\n",
        "\n",
        "        conv_trans = tf.nn.conv3d_transpose(x, w,\n",
        "                                            output_shape = output_shape,\n",
        "                                            strides = [1] + stride + [1],\n",
        "                                            padding = pad)\n",
        "\n",
        "        if if_bias:\n",
        "            if bias_initializer is None:\n",
        "                print(\"Initializing biases\")\n",
        "                conv_trans = conv_trans + bias_variable([num_output], trainable=trainable)\n",
        "            else:\n",
        "                print(\"Load biases\")\n",
        "                conv_trans = conv_trans + bias_variable([num_output], trainable=trainable, bias_initializer=bias_initializer)\n",
        "\n",
        "\n",
        "        return conv_trans\n",
        "\n",
        "def conv3d_transpose_specNorm(x, num_output, kernel_size = (4,4), stride= (1,1), pad='SAME', if_bias=True,\n",
        "                     reuse=False, scope = \"conv3d_transpose\", trainable = True, weight_initializer=None,\n",
        "                     bias_initializer=None, u_weight=None, weight_initializer_type=tf.random_normal_initializer(stddev=0.02)):\n",
        "\n",
        "    print(scope)\n",
        "    with tf.variable_scope(scope, reuse = reuse):\n",
        "        if weight_initializer is None:\n",
        "            print(\"Initializing weights\")\n",
        "            w = tf.get_variable(name='weights',\n",
        "                                shape = kernel_size + [num_output] + [x.get_shape().as_list()[-1]],\n",
        "                                initializer=weight_initializer_type,\n",
        "                                dtype = tf.float32, trainable=trainable)\n",
        "        else:\n",
        "            print(\"Loading weights\")\n",
        "            w = tf.get_variable(name='weights',\n",
        "                                initializer=weight_initializer,\n",
        "                                dtype = tf.float32, trainable=trainable)\n",
        "        print(\"W \" + str(w.get_shape()))\n",
        "        output_shape = [tf.shape(x)[0], tf.shape(x)[1] * stride[0], tf.shape(x)[2] * stride[1], tf.shape(x)[3] * stride[2], num_output]\n",
        "\n",
        "        conv_trans = tf.nn.conv3d_transpose(x, spectral_norm(w, 1, u_weight),\n",
        "                                            output_shape = output_shape,\n",
        "                                            strides = [1] + stride + [1],\n",
        "                                            padding = pad)\n",
        "\n",
        "        if if_bias:\n",
        "            if bias_initializer is None:\n",
        "                print(\"Initializing biases\")\n",
        "                conv_trans = conv_trans + bias_variable([num_output], trainable=trainable)\n",
        "            else:\n",
        "                print(\"Load biases\")\n",
        "                conv_trans = conv_trans + bias_variable([num_output], trainable=trainable, bias_initializer=bias_initializer)\n",
        "\n",
        "\n",
        "        return conv_trans\n",
        "\n",
        "def fully_connected(input_, output_size, scope = 'fully_connected', if_bias=True,\n",
        "                    weight_initializer=None, bias_initializer=None,  reuse = False, trainable = True,\n",
        "                    weight_initializer_type=tf.random_normal_initializer(stddev=0.02)):\n",
        "    print(scope)\n",
        "    if (type(input_)== np.ndarray):\n",
        "        shape = input_.shape\n",
        "    else:\n",
        "        shape = input_.get_shape().as_list()\n",
        "        # shape = tf.shape(input_).value.as_list()\n",
        "    with tf.variable_scope(scope, reuse = reuse):\n",
        "        if weight_initializer is None:\n",
        "            print(\"Initializing weights\")\n",
        "            matrix = tf.get_variable(\"weights\", [shape[-1], output_size], initializer=weight_initializer_type, dtype = tf.float32, trainable=trainable)\n",
        "        else:\n",
        "            print(\"Loading weights\")\n",
        "            matrix = tf.get_variable(\"weights\", initializer=weight_initializer, dtype=tf.float32, trainable=trainable)\n",
        "\n",
        "        fc = tf.matmul(input_, matrix)\n",
        "        if if_bias:\n",
        "            if bias_initializer is None:\n",
        "                print(\"Initializing biases\")\n",
        "                fc = fc + bias_variable([output_size], trainable=trainable)\n",
        "            else:\n",
        "                print(\"Load biases\")\n",
        "                fc = fc + bias_variable([output_size], bias_initializer, trainable=trainable)\n",
        "        return fc\n",
        "\n",
        "def save_txt_file(pred, name, SAVE_DIR):\n",
        "    with open(os.path.join(SAVE_DIR, \"{0}.txt\".format(name)), 'w') as fp:\n",
        "        for i in pred:\n",
        "            # print(tuple(point.tolist()))\n",
        "            fp.write(\"{0}\\n\".format(i))\n",
        "\n",
        "def transform_tensor_to_image (tensor):\n",
        "    t = tf.transpose(tensor, [0 , 2, 1, 3])\n",
        "    return t[:,::-1, :, :]\n",
        "\n",
        "def transform_voxel_to_match_image(tensor):\n",
        "    tensor = tf.transpose(tensor, [0, 2, 1, 3, 4])\n",
        "    tensor = tensor[:, ::-1, :, :, :]\n",
        "    return tensor\n",
        "\n",
        "def transform_image_to_match_voxel(tensor):\n",
        "    tensor = tf.transpose(tensor, [0, 2, 1, 3])\n",
        "    tensor = tensor[:, ::-1, :, :]\n",
        "    return tensor\n",
        "\n",
        "def np_transform_tensor_to_image (tensor):\n",
        "    t = np.transpose(tensor, [0, 2, 1, 3])\n",
        "    return t\n",
        "\n",
        "try:\n",
        "  image_summary = tf.image_summary\n",
        "  scalar_summary = tf.scalar_summary\n",
        "  histogram_summary = tf.histogram_summary\n",
        "  merge_summary = tf.merge_summary\n",
        "  SummaryWriter = tf.train.SummaryWriter\n",
        "except:\n",
        "  image_summary = tf.summary.image\n",
        "  scalar_summary = tf.summary.scalar\n",
        "  histogram_summary = tf.summary.histogram\n",
        "  merge_summary = tf.summary.merge\n",
        "  SummaryWriter = tf.summary.FileWriter\n",
        "\n",
        "def sigmoid_cross_entropy_with_logits(x, y):\n",
        "    try:\n",
        "        return tf.nn.sigmoid_cross_entropy_with_logits(logits=x, labels=y)\n",
        "    except:\n",
        "        return tf.nn.sigmoid_cross_entropy_with_logits(logits=x, targets=y)\n",
        "\n",
        "#===========================================================================================================\n",
        "#Activation functions\n",
        "#===========================================================================================================\n",
        "\n",
        "def lrelu(x, leak=0.2, name=\"lrelu\"):\n",
        "  return tf.maximum(x, leak*x)\n",
        "\n",
        "#===========================================================================================================\n",
        "#Normalization\n",
        "#===========================================================================================================\n",
        "def AdaIn(features, scale, bias):\n",
        "    \"\"\"\n",
        "    Adaptive instance normalization component. Works with both 4D and 5D tensors\n",
        "    :features: features to be normalized\n",
        "    :scale: scaling factor. This would otherwise be calculated as the sigma from a \"style\" features in style transfer\n",
        "    :bias: bias factor. This would otherwise be calculated as the mean from a \"style\" features in style transfer\n",
        "    \"\"\"\n",
        "\n",
        "    mean, variance = tf.nn.moments(features, list(range(len(features.get_shape())))[1:-1],\n",
        "                                   keep_dims=True)  # Only consider spatial dimension\n",
        "    sigma = tf.rsqrt(variance + 1e-8)\n",
        "    normalized = (features - mean) * sigma\n",
        "    scale_broadcast = tf.reshape(scale, tf.shape(mean))\n",
        "    bias_broadcast = tf.reshape(bias, tf.shape(mean))\n",
        "    normalized = scale_broadcast * normalized\n",
        "    normalized += bias_broadcast\n",
        "    return normalized\n",
        "\n",
        "def instance_norm(input, name=\"instance_norm\", return_mean=False):\n",
        "    \"\"\"\n",
        "    Taken from https://github.com/xhujoy/CycleGAN-tensorflow/blob/master/module.py\n",
        "    :param input:\n",
        "    :param name:\n",
        "    :return:\n",
        "    \"\"\"\n",
        "    with tf.variable_scope(name):\n",
        "        depth = input.get_shape()[3]\n",
        "        scale = tf.get_variable(\"scale\", [depth],\n",
        "                                initializer=tf.random_normal_initializer(1.0, 0.02, dtype=tf.float32))\n",
        "        offset = tf.get_variable(\"offset\", [depth], initializer=tf.constant_initializer(0.0))\n",
        "        mean, variance = tf.nn.moments(input, axes=[1, 2], keep_dims=True)\n",
        "        epsilon = 1e-5\n",
        "        inv = tf.rsqrt(variance + epsilon)\n",
        "        normalized = (input - mean) * inv\n",
        "        if return_mean:\n",
        "            return scale * normalized + offset, mean, variance\n",
        "        else:\n",
        "            return scale * normalized + offset\n",
        "\n",
        "def l2_norm(v, eps=1e-12):\n",
        "    return v / (tf.reduce_sum(v ** 2) ** 0.5 + eps)\n",
        "\n",
        "def spectral_norm(w, iteration=1, u_weight=None):\n",
        "    w_shape = w.shape.as_list()\n",
        "    w = tf.reshape(w, [-1, w_shape[-1]])\n",
        "    if u_weight is None:\n",
        "        u = tf.get_variable(\"u\", [1, w_shape[-1]], initializer=tf.truncated_normal_initializer(), trainable=False)\n",
        "    else:\n",
        "        u = u_weight\n",
        "\n",
        "    u_hat = u\n",
        "    v_hat = None\n",
        "    for i in range(iteration):\n",
        "        \"\"\"\n",
        "        power iteration\n",
        "        Usually iteration = 1 will be enough\n",
        "        \"\"\"\n",
        "        v_ = tf.matmul(u_hat, tf.transpose(w))\n",
        "        v_hat = l2_norm(v_)\n",
        "\n",
        "        u_ = tf.matmul(v_hat, w)\n",
        "        u_hat = l2_norm(u_)\n",
        "\n",
        "    sigma = tf.matmul(tf.matmul(v_hat, w), tf.transpose(u_hat))\n",
        "    w_norm = w / sigma\n",
        "\n",
        "    with tf.control_dependencies([u.assign(u_hat)]):\n",
        "        w_norm = tf.reshape(w_norm, w_shape)\n",
        "\n",
        "    return w_norm\n",
        "\n",
        "\n",
        "#===========================================================================================================\n",
        "#Convolutions\n",
        "#===========================================================================================================\n",
        "def conv_out_size_same(size, stride):\n",
        "  return int(math.ceil(float(size) / float(stride)))\n",
        "\n",
        "\n",
        "def get_weight(shape, gain=np.sqrt(2), use_wscale=False, fan_in=None):\n",
        "    if fan_in is None:\n",
        "        fan_in = np.prod(shape[:-1])\n",
        "    print (\"current\", shape[:-1], fan_in)\n",
        "    std = gain / np.sqrt(fan_in) # He init\n",
        "\n",
        "    if use_wscale:\n",
        "        wscale = tf.constant(np.float32(std), name='wscale')\n",
        "        return tf.get_variable('weight', shape=shape, initializer=tf.initializers.random_normal()) * wscale\n",
        "    else:\n",
        "        return tf.get_variable('weight', shape=shape, initializer=tf.initializers.random_normal(0, std))\n",
        "\n",
        "\n",
        "def conv2d(input_, output_dim,\n",
        "       k_h=5, k_w=5, d_h=2, d_w=2, stddev=0.02,\n",
        "       name=\"conv2d\", padding='SAME'):\n",
        "    with tf.variable_scope(name):\n",
        "        w = tf.get_variable('weights', [k_h, k_w, input_.get_shape()[-1], output_dim],\n",
        "                  initializer=tf.truncated_normal_initializer(stddev=stddev))\n",
        "        conv = tf.nn.conv2d(input_, w, strides=[1, d_h, d_w, 1], padding=padding)\n",
        "\n",
        "        biases = tf.get_variable('biases', [output_dim], initializer=tf.constant_initializer(0.0))\n",
        "        conv = tf.reshape(tf.nn.bias_add(conv, biases), tf.shape(conv))\n",
        "\n",
        "        return conv\n",
        "\n",
        "\n",
        "def conv2d_specNorm(input_, output_dim,\n",
        "       k_h=5, k_w=5, d_h=2, d_w=2, stddev=0.02,\n",
        "       name=\"conv2dSpectral\", padding='SAME'):\n",
        "  with tf.variable_scope(name):\n",
        "    w = tf.get_variable('weights', [k_h, k_w, input_.get_shape()[-1], output_dim],\n",
        "              initializer=tf.truncated_normal_initializer(stddev=stddev))\n",
        "    conv = tf.nn.conv2d(input_, spectral_norm(w), strides=[1, d_h, d_w, 1], padding=padding)\n",
        "\n",
        "    biases = tf.get_variable('biases', [output_dim], initializer=tf.constant_initializer(0.0))\n",
        "    conv = tf.reshape(tf.nn.bias_add(conv, biases), tf.shape(conv))\n",
        "\n",
        "    return conv\n",
        "\n",
        "def conv3d(input_, output_dim,\n",
        "       k_h=5, k_w=5, k_d=5, d_h=2, d_w=2, d_d=2, stddev=0.02,\n",
        "       name=\"conv3d\", padding='SAME'):\n",
        "  with tf.variable_scope(name):\n",
        "    w = tf.get_variable('weights', [k_h, k_w, k_d, input_.get_shape()[-1], output_dim],\n",
        "              initializer=tf.truncated_normal_initializer(stddev=stddev))\n",
        "    conv = tf.nn.conv3d(input_, w, strides=[1, d_h, d_w, d_d, 1], padding=padding)\n",
        "\n",
        "    biases = tf.get_variable('biases', [output_dim], initializer=tf.constant_initializer(0.0))\n",
        "    conv = tf.reshape(tf.nn.bias_add(conv, biases), tf.shape(conv))\n",
        "\n",
        "    return conv\n",
        "\n",
        "def conv3d_specNorm(input_, output_dim,\n",
        "       k_h=5, k_w=5, k_d=5, d_h=2, d_w=2, d_d=2, stddev=0.02,\n",
        "       name=\"conv3dSpectral\", padding='SAME'):\n",
        "  with tf.variable_scope(name):\n",
        "    w = tf.get_variable('weights', [k_h, k_w, k_d, input_.get_shape()[-1], output_dim],\n",
        "              initializer=tf.truncated_normal_initializer(stddev=stddev))\n",
        "    conv = tf.nn.conv3d(input_, spectral_norm(w), strides=[1, d_h, d_w, d_d, 1], padding=padding)\n",
        "\n",
        "    biases = tf.get_variable('biases', [output_dim], initializer=tf.constant_initializer(0.0))\n",
        "    conv = tf.reshape(tf.nn.bias_add(conv, biases), tf.shape(conv))\n",
        "\n",
        "    return conv\n",
        "\n",
        "def deconv2d(input_, output_shape,\n",
        "       k_h=5, k_w=5, d_h=2, d_w=2, stddev=0.02,\n",
        "       name=\"deconv2d\", with_w=False):\n",
        "  with tf.variable_scope(name):\n",
        "    # filter : [height, width, output_channels, in_channels]\n",
        "    w = tf.get_variable('weights', [k_h, k_w, output_shape[-1], input_.get_shape()[-1]],\n",
        "              initializer=tf.random_normal_initializer(stddev=stddev))\n",
        "\n",
        "\n",
        "    deconv = tf.nn.conv2d_transpose(input_, w, output_shape=output_shape, strides=[1, d_h, d_w, 1])\n",
        "\n",
        "    biases = tf.get_variable('biases', [output_shape[-1]], initializer=tf.constant_initializer(0.0))\n",
        "    deconv = tf.reshape(tf.nn.bias_add(deconv, biases), tf.shape(deconv))\n",
        "\n",
        "    if with_w:\n",
        "      return deconv, w, biases\n",
        "    else:\n",
        "      return deconv\n",
        "\n",
        "\n",
        "def deconv2d_specNorm(input_, output_shape,\n",
        "             k_h=5, k_w=5, d_h=2, d_w=2, stddev=0.02,\n",
        "             name=\"deconv2d\", with_w=False):\n",
        "    with tf.variable_scope(name):\n",
        "        # filter : [height, width, output_channels, in_channels]\n",
        "        w = tf.get_variable('weights', [k_h, k_w, output_shape[-1], input_.get_shape()[-1]],\n",
        "                            initializer=tf.random_normal_initializer(stddev=stddev))\n",
        "        deconv = tf.nn.conv2d_transpose(input_, spectral_norm(w), output_shape=output_shape,\n",
        "                                        strides=[1, d_h, d_w, 1])\n",
        "\n",
        "        biases = tf.get_variable('biases', [output_shape[-1]], initializer=tf.constant_initializer(0.0))\n",
        "        deconv = tf.reshape(tf.nn.bias_add(deconv, biases), tf.shape(deconv))\n",
        "\n",
        "        if with_w:\n",
        "            return deconv, w, biases\n",
        "        else:\n",
        "            return deconv\n",
        "\n",
        "\n",
        "def deconv3d(input_, output_shape,\n",
        "             k_h=5, k_w=5, k_d=5, d_h=2, d_w=2, d_d=2, stddev=0.02,\n",
        "             name=\"deconv3d\", with_w=False):\n",
        "  with tf.variable_scope(name):\n",
        "    # filter : [height, width, output_channels, in_channels]\n",
        "    w = tf.get_variable('weights', [k_h, k_w, k_d, output_shape[-1], input_.get_shape()[-1]],\n",
        "                        initializer=tf.random_normal_initializer(stddev=stddev))\n",
        "\n",
        "    deconv = tf.nn.conv3d_transpose(input_, w, output_shape=output_shape,\n",
        "                                      strides=[1, d_h, d_w, d_d, 1])\n",
        "\n",
        "\n",
        "    biases = tf.get_variable('biases', [output_shape[-1]], initializer=tf.constant_initializer(0.0))\n",
        "    deconv = tf.reshape(tf.nn.bias_add(deconv, biases), tf.shape(deconv))\n",
        "\n",
        "    if with_w:\n",
        "      return deconv, w, biases\n",
        "    else:\n",
        "      return deconv\n",
        "\n",
        "def deconv3d_specNorm(input_, output_shape,\n",
        "             k_h=5, k_w=5, k_d=5, d_h=2, d_w=2, d_d=2, stddev=0.02,\n",
        "             name=\"deconv3dSpectral\", with_w=False):\n",
        "  with tf.variable_scope(name):\n",
        "    w = tf.get_variable('weights', [k_h, k_w, k_d, output_shape[-1], input_.get_shape()[-1]],\n",
        "              initializer=tf.truncated_normal_initializer(stddev=stddev))\n",
        "    deconv = tf.nn.conv3d_transpose(input_, spectral_norm(w), output_shape=output_shape, strides=[1, d_h, d_w, d_d, 1], padding='SAME')\n",
        "\n",
        "    biases = tf.get_variable('biases', [output_shape[-1]], initializer=tf.constant_initializer(0.0))\n",
        "    deconv = tf.reshape(tf.nn.bias_add(deconv, biases), tf.shape(deconv))\n",
        "\n",
        "    if with_w:\n",
        "      return deconv, w, biases\n",
        "    else:\n",
        "      return deconv\n",
        "\n",
        "def linear(input_, output_size, scope=None, stddev=0.02, bias_start=0.0, with_w=False):\n",
        "  shape = input_.get_shape().as_list()\n",
        "  with tf.variable_scope(scope or \"Linear\"):\n",
        "    matrix = tf.get_variable(\"weights\", [shape[1], output_size], tf.float32,\n",
        "                 tf.random_normal_initializer(stddev=stddev))\n",
        "    bias = tf.get_variable(\"biases\", [output_size],\n",
        "      initializer=tf.constant_initializer(bias_start))\n",
        "    if with_w:\n",
        "      return tf.matmul(input_, matrix) + bias, matrix, bias\n",
        "    else:\n",
        "      return tf.matmul(input_, matrix) + bias\n",
        "\n",
        "def linear_specNorm(input_, output_size, scope=None, stddev=0.02, bias_start=0.0, with_w=False):\n",
        "  shape = input_.get_shape().as_list()\n",
        "\n",
        "  with tf.variable_scope(scope or \"Linear\"):\n",
        "    matrix = spectral_norm(tf.get_variable(\"weights\", [shape[1], output_size], tf.float32,\n",
        "                 tf.random_normal_initializer(stddev=stddev)))\n",
        "    bias = tf.get_variable(\"biases\", [output_size],\n",
        "      initializer=tf.constant_initializer(bias_start))\n",
        "    if with_w:\n",
        "      return tf.matmul(input_, matrix) + bias, matrix, bias\n",
        "    else:\n",
        "      return tf.matmul(input_, matrix) + bias\n",
        "\n",
        "\n",
        "def flatten(x) :\n",
        "    return tf.layers.flatten(x)\n",
        "\n",
        "\n",
        "def tf_repeat(x, n_repeats):\n",
        "    #Repeat X for n_repeats time along 0 axis\n",
        "    #Return a 1D tensor of total number of elements\n",
        "    rep = tf.ones(shape=[1, n_repeats], dtype = 'int32')\n",
        "    x = tf.matmul(tf.reshape(x, (-1,1)), rep)\n",
        "    return tf.reshape(x, [-1])\n",
        "\n",
        "def tf_interpolate(voxel, x, y, z, out_size):\n",
        "    \"\"\"\n",
        "    Trilinear interpolation for batch of voxels\n",
        "    :param voxel: The whole voxel grid\n",
        "    :param x,y,z: indices of voxel\n",
        "    :param output_size: output size of voxel\n",
        "    :return:\n",
        "    \"\"\"\n",
        "    batch_size = tf.shape(voxel)[0]\n",
        "    height = tf.shape(voxel)[1]\n",
        "    width = tf.shape(voxel)[2]\n",
        "    depth = tf.shape(voxel)[3]\n",
        "    n_channels = tf.shape(voxel)[4]\n",
        "\n",
        "    x = tf.cast(x, 'float32')\n",
        "    y = tf.cast(y, 'float32')\n",
        "    z = tf.cast(z, 'float32')\n",
        "\n",
        "    out_height = out_size[1]\n",
        "    out_width = out_size[2]\n",
        "    out_depth = out_size[3]\n",
        "    out_channel = out_size[4]\n",
        "\n",
        "    zero = tf.zeros([], dtype='int32')\n",
        "    max_y = tf.cast(height - 1, 'int32')\n",
        "    max_x = tf.cast(width - 1, 'int32')\n",
        "    max_z = tf.cast(depth - 1, 'int32')\n",
        "\n",
        "    # do sampling\n",
        "    x0 = tf.cast(tf.floor(x), 'int32')\n",
        "    x1 = x0 + 1\n",
        "    y0 = tf.cast(tf.floor(y), 'int32')\n",
        "    y1 = y0 + 1\n",
        "    z0 = tf.cast(tf.floor(z), 'int32')\n",
        "    z1 = z0 + 1\n",
        "\n",
        "    x0 = tf.clip_by_value(x0, zero, max_x)\n",
        "    x1 = tf.clip_by_value(x1, zero, max_x)\n",
        "    y0 = tf.clip_by_value(y0, zero, max_y)\n",
        "    y1 = tf.clip_by_value(y1, zero, max_y)\n",
        "    z0 = tf.clip_by_value(z0, zero, max_z)\n",
        "    z1 = tf.clip_by_value(z1, zero, max_z)\n",
        "\n",
        "    #A 1D tensor of base indicies describe First index for each shape/map in the whole batch\n",
        "    #tf.range(batch_size) * width * height * depth : Element to repeat. Each selement in the list is incremented by width*height*depth amount\n",
        "    # out_height * out_width * out_depth: n of repeat. Create chunks of out_height*out_width*out_depth length with the same value created by tf.rage(batch_size) *width*height*dept\n",
        "    base = tf_repeat(tf.range(batch_size) * width * height * depth, out_height * out_width * out_depth)\n",
        "\n",
        "    #Find the Z element of each index\n",
        "\n",
        "    base_z0 = base + z0 * width * height\n",
        "    base_z1 = base + z1 * width * height\n",
        "    #Find the Y element based on Z\n",
        "    base_z0_y0 = base_z0 + y0 * width\n",
        "    base_z0_y1 = base_z0 + y1 * width\n",
        "    base_z1_y0 = base_z1 + y0 * width\n",
        "    base_z1_y1 = base_z1 + y1 * width\n",
        "\n",
        "    # Find the X element based on Y, Z for Z=0\n",
        "    idx_a = base_z0_y0 + x0\n",
        "    idx_b = base_z0_y1 + x0\n",
        "    idx_c = base_z0_y0 + x1\n",
        "    idx_d = base_z0_y1 + x1\n",
        "    # Find the X element based on Y,Z for Z =1\n",
        "    idx_e = base_z1_y0 + x0\n",
        "    idx_f = base_z1_y1 + x0\n",
        "    idx_g = base_z1_y0 + x1\n",
        "    idx_h = base_z1_y1 + x1\n",
        "\n",
        "    # use indices to lookup pixels in the flat image and restore\n",
        "    # channels dim\n",
        "    voxel_flat = tf.reshape(voxel, [-1, n_channels])\n",
        "    voxel_flat = tf.cast(voxel_flat, 'float32')\n",
        "    Ia = tf.gather(voxel_flat, idx_a)\n",
        "    Ib = tf.gather(voxel_flat, idx_b)\n",
        "    Ic = tf.gather(voxel_flat, idx_c)\n",
        "    Id = tf.gather(voxel_flat, idx_d)\n",
        "    Ie = tf.gather(voxel_flat, idx_e)\n",
        "    If = tf.gather(voxel_flat, idx_f)\n",
        "    Ig = tf.gather(voxel_flat, idx_g)\n",
        "    Ih = tf.gather(voxel_flat, idx_h)\n",
        "\n",
        "    # and finally calculate interpolated values\n",
        "    x0_f = tf.cast(x0, 'float32')\n",
        "    x1_f = tf.cast(x1, 'float32')\n",
        "    y0_f = tf.cast(y0, 'float32')\n",
        "    y1_f = tf.cast(y1, 'float32')\n",
        "    z0_f = tf.cast(z0, 'float32')\n",
        "    z1_f = tf.cast(z1, 'float32')\n",
        "\n",
        "    #First slice XY along Z where z=0\n",
        "    wa = tf.expand_dims(((x1_f - x) * (y1_f - y) * (z1_f-z)), 1)\n",
        "    wb = tf.expand_dims(((x1_f - x) * (y - y0_f) * (z1_f-z)), 1)\n",
        "    wc = tf.expand_dims(((x - x0_f) * (y1_f - y) * (z1_f-z)), 1)\n",
        "    wd = tf.expand_dims(((x - x0_f) * (y - y0_f) * (z1_f-z)), 1)\n",
        "    # First slice XY along Z where z=1\n",
        "    we = tf.expand_dims(((x1_f - x) * (y1_f - y) * (z-z0_f)), 1)\n",
        "    wf = tf.expand_dims(((x1_f - x) * (y - y0_f) * (z-z0_f)), 1)\n",
        "    wg = tf.expand_dims(((x - x0_f) * (y1_f - y) * (z-z0_f)), 1)\n",
        "    wh = tf.expand_dims(((x - x0_f) * (y - y0_f) * (z-z0_f)), 1)\n",
        "\n",
        "\n",
        "    output = tf.add_n([wa * Ia, wb * Ib, wc * Ic, wd * Id,  we * Ie, wf * If, wg * Ig, wh * Ih])\n",
        "    return output\n",
        "\n",
        "def tf_voxel_meshgrid(height, width, depth, homogeneous = False):\n",
        "    with tf.variable_scope('voxel_meshgrid'):\n",
        "        #Because 'ij' ordering is used for meshgrid, z_t and x_t are swapped (Think about order in 'xy' VS 'ij'\n",
        "        z_t, y_t, x_t = tf.meshgrid(tf.range(depth, dtype = tf.float32),\n",
        "                                    tf.range(height, dtype = tf.float32),\n",
        "                                    tf.range(width, dtype = tf.float32), indexing='ij')\n",
        "        #Reshape into a big list of slices one after another along the X,Y,Z direction\n",
        "        x_t_flat = tf.reshape(x_t, (1, -1))\n",
        "        y_t_flat = tf.reshape(y_t, (1, -1))\n",
        "        z_t_flat = tf.reshape(z_t, (1, -1))\n",
        "\n",
        "        #Vertical stack to create a (3,N) matrix for X,Y,Z coordinates\n",
        "        grid = tf.concat([x_t_flat, y_t_flat, z_t_flat], axis=0)\n",
        "        if homogeneous:\n",
        "            ones = tf.ones_like(x_t_flat)\n",
        "            grid = tf.concat([grid, ones], axis = 0)\n",
        "        return grid\n",
        "\n",
        "def tf_rotation_around_grid_centroid(view_params, shapenet_viewer = False):\n",
        "    #This function returns a rotation matrix around a center with y-axis being the up vector, and a scale matrix.\n",
        "    #It first rotates the matrix by the azimuth angle (theta) around y, then around X-axis by elevation angle (gamma)\n",
        "    #return a rotation matrix in homogenous coordinate\n",
        "    #The default Open GL camera is to looking towards the negative Z direction\n",
        "    #This function is suitable when the silhoutte projection is done along the Z direction\n",
        "\n",
        "    batch_size = tf.shape(view_params)[0]\n",
        "\n",
        "    azimuth    = tf.reshape(view_params[:, 0], (batch_size, 1, 1))\n",
        "    elevation  = tf.reshape(view_params[:, 1], (batch_size, 1, 1))\n",
        "\n",
        "    # azimuth = azimuth\n",
        "    if shapenet_viewer == False:\n",
        "        azimuth = (azimuth - tf.constant(math.pi * 0.5))\n",
        "\n",
        "    #========================================================\n",
        "    #Because tensorflow does not allow tensor item replacement\n",
        "    #A new matrix needs to be created from scratch by concatenating different vectors into rows and stacking them up\n",
        "    #Batch Rotation Y matrixes\n",
        "    ones = tf.ones_like(azimuth)\n",
        "    zeros = tf.zeros_like(azimuth)\n",
        "    batch_Rot_Y = tf.concat([\n",
        "        tf.concat([tf.cos(azimuth),  zeros, -tf.sin(azimuth), zeros], axis=2),\n",
        "        tf.concat([zeros, ones,  zeros,zeros], axis=2),\n",
        "        tf.concat([tf.sin(azimuth),  zeros, tf.cos(azimuth), zeros], axis=2),\n",
        "        tf.concat([zeros, zeros, zeros, ones], axis=2)], axis=1)\n",
        "\n",
        "    #Batch Rotation Z matrixes\n",
        "    batch_Rot_Z = tf.concat([\n",
        "        tf.concat([tf.cos(elevation),  tf.sin(elevation),  zeros, zeros], axis=2),\n",
        "        tf.concat([-tf.sin(elevation), tf.cos(elevation),  zeros, zeros], axis=2),\n",
        "        tf.concat([zeros, zeros, ones,  zeros], axis=2),\n",
        "        tf.concat([zeros, zeros, zeros, ones], axis=2)], axis=1)\n",
        "\n",
        "\n",
        "    transformation_matrix = tf.matmul(batch_Rot_Z, batch_Rot_Y)\n",
        "    if tf.shape(view_params)[1] == 2:\n",
        "        return transformation_matrix\n",
        "    else:\n",
        "    #Batch Scale matrixes:\n",
        "        scale = tf.reshape(view_params[:, 2], (batch_size, 1, 1))\n",
        "        batch_Scale= tf.concat([\n",
        "            tf.concat([scale,  zeros,  zeros, zeros], axis=2),\n",
        "            tf.concat([zeros, scale,  zeros, zeros], axis=2),\n",
        "            tf.concat([zeros, zeros,  scale,  zeros], axis=2),\n",
        "            tf.concat([zeros, zeros,  zeros, ones], axis=2)], axis=1)\n",
        "    return transformation_matrix, batch_Scale\n",
        "\n",
        "def tf_rotation_resampling(voxel_array, transformation_matrix, params, Scale_matrix = None, size=64, new_size=128):\n",
        "    \"\"\"\n",
        "    Batch transformation and resampling function\n",
        "    :param voxel_array: batch of voxels. Shape = [batch_size, height, width, depth, features]\n",
        "    :param transformation_matrix: Rotation matrix. Shape = [batch_size, height, width, depth, features]\n",
        "    :param size: original size of the voxel array\n",
        "    :param new_size: size of the resampled array\n",
        "    :return: transformed voxel array\n",
        "    \"\"\"\n",
        "    batch_size = tf.shape(voxel_array)[0]\n",
        "    n_channels = voxel_array.get_shape()[4].value\n",
        "    target = tf.zeros([ batch_size, new_size, new_size, new_size])\n",
        "    #Aligning the centroid of the object (voxel grid) to origin for rotation,\n",
        "    #then move the centroid back to the original position of the grid centroid\n",
        "    T = tf.constant([[1,0,0, -size * 0.5],\n",
        "                  [0,1,0, -size * 0.5],\n",
        "                  [0,0,1, -size * 0.5],\n",
        "                  [0,0,0,1]])\n",
        "    T = tf.tile(tf.reshape(T, (1, 4, 4)), [batch_size, 1, 1])\n",
        "\n",
        "    # However, since the rotated grid might be out of bound for the original grid size,\n",
        "    # move the rotated grid to a new bigger grid\n",
        "    T_new_inv = tf.constant([[1, 0, 0, new_size * 0.5],\n",
        "                             [0, 1, 0, new_size * 0.5],\n",
        "                             [0, 0, 1, new_size * 0.5],\n",
        "                             [0, 0, 0, 1]])\n",
        "    T_new_inv = tf.tile(tf.reshape(T_new_inv, (1, 4, 4)), [batch_size, 1, 1])\n",
        "\n",
        "\n",
        "    # Add the actual shifting in x and y dimension accoding to input param\n",
        "    x_shift = tf.reshape(params[:, 3], (batch_size, 1, 1))\n",
        "    y_shift = tf.reshape(params[:, 4], (batch_size, 1, 1))\n",
        "    z_shift = tf.reshape(params[:, 5], (batch_size, 1, 1))\n",
        "    # ========================================================\n",
        "    # Because tensorflow does not allow tensor item replacement\n",
        "    # A new matrix needs to be created from scratch by concatenating different vectors into rows and stacking them up\n",
        "    # Batch Rotation Y matrixes\n",
        "    ones = tf.ones_like(x_shift)\n",
        "    zeros = tf.zeros_like(x_shift)\n",
        "\n",
        "    T_translate = tf.concat([\n",
        "        tf.concat([ones, zeros, zeros, x_shift], axis=2),\n",
        "        tf.concat([zeros, ones, zeros, y_shift], axis=2),\n",
        "        tf.concat([zeros, zeros, ones, z_shift], axis=2),\n",
        "        tf.concat([zeros, zeros, zeros, ones], axis=2)], axis=1)\n",
        "    total_M = tf.matmul(tf.matmul(tf.matmul(tf.matmul(T_new_inv, T_translate), Scale_matrix), transformation_matrix), T)\n",
        "\n",
        "\n",
        "    try:\n",
        "        total_M = tf.matrix_inverse(total_M)\n",
        "\n",
        "        total_M = total_M[:, 0:3, :] #Ignore the homogenous coordinate so the results are 3D vectors\n",
        "        grid = tf_voxel_meshgrid(new_size, new_size, new_size, homogeneous=True)\n",
        "        grid = tf.tile(tf.reshape(grid, (1, tf.to_int32(grid.get_shape()[0]) , tf.to_int32(grid.get_shape()[1]))), [batch_size, 1, 1])\n",
        "        grid_transform = tf.matmul(total_M, grid)\n",
        "        x_s_flat = tf.reshape(grid_transform[:, 0, :], [-1])\n",
        "        y_s_flat = tf.reshape(grid_transform[:, 1, :], [-1])\n",
        "        z_s_flat = tf.reshape(grid_transform[:, 2, :], [-1])\n",
        "        input_transformed = tf_interpolate(voxel_array, x_s_flat, y_s_flat, z_s_flat,[batch_size, new_size, new_size, new_size, n_channels])\n",
        "        target= tf.reshape(input_transformed, [batch_size, new_size, new_size, new_size, n_channels])\n",
        "\n",
        "        return target, grid_transform\n",
        "    except tf.InvalidArgumentError:\n",
        "        return None\n",
        "\n",
        "def tf_3D_transform(voxel_array, view_params, size=64, new_size=128, shapenet_viewer=False):\n",
        "    \"\"\"\n",
        "    Wrapper function to do 3D transformation\n",
        "    :param voxel_array: batch of voxels. Shape = [batch_size, height, width, depth, features]\n",
        "    :param transformation_matrix: Rotation matrix. Shape = [batch_size, height, width, depth, features]\n",
        "    :param size: original size of the voxel array\n",
        "    :param new_size: size of the resampled array\n",
        "    :return: transformed voxel array\n",
        "    \"\"\"\n",
        "    M, S = tf_rotation_around_grid_centroid(view_params[:, :3], shapenet_viewer=shapenet_viewer)\n",
        "    target, grids = tf_rotation_resampling(voxel_array, M, params=view_params, Scale_matrix=S, size = size, new_size=new_size)\n",
        "    return target\n",
        "\n",
        "def generate_random_rotation_translation(batch_size, elevation_low=10, elevation_high=170, azimuth_low=0, azimuth_high=359,\n",
        "                                         transX_low=-3, transX_high=3,\n",
        "                                         transY_low=-3, transY_high=3,\n",
        "                                         transZ_low=-3, transZ_high=3,\n",
        "                                         scale_low=1.0, scale_high=1.0,\n",
        "                                         with_translation=False, with_scale=False):\n",
        "    params = np.zeros((batch_size, 6))\n",
        "    column = np.arange(0, batch_size)\n",
        "    azimuth = np.random.randint(azimuth_low, azimuth_high, (batch_size)).astype(np.float) * math.pi / 180.0\n",
        "    temp = np.random.randint(elevation_low, elevation_high, (batch_size))\n",
        "    elevation = (90. - temp.astype(np.float)) * math.pi / 180.0\n",
        "    params[column, 0] = azimuth\n",
        "    params[column, 1] = elevation\n",
        "\n",
        "    if with_translation:\n",
        "        shift_x = transX_low + np.random.random(batch_size) * (transX_high - transX_low)\n",
        "        shift_y = transY_low + np.random.random(batch_size) * (transY_high - transY_low)\n",
        "        shift_z = transZ_low + np.random.random(batch_size) * (transZ_high - transZ_low)\n",
        "        params[column, 3] = shift_x\n",
        "        params[column, 4] = shift_y\n",
        "        params[column, 5] = shift_z\n",
        "\n",
        "    if with_scale:\n",
        "        scale = float(np.random.uniform(scale_low, scale_high))\n",
        "        params[column, 2] = scale\n",
        "    else:\n",
        "        params[column, 2] = 1.0\n",
        "\n",
        "    return params\n",
        "\n",
        "\n",
        "pp = pprint.PrettyPrinter()\n",
        "\n",
        "get_stddev = lambda x, k_h, k_w: 1/math.sqrt(k_w*k_h*x.get_shape()[-1])\n",
        "\n",
        "def show_all_variables():\n",
        "  model_vars = tf.trainable_variables()\n",
        "  slim.model_analyzer.analyze_vars(model_vars, print_info=True)\n",
        "\n",
        "def get_image(image_path, input_height, input_width,\n",
        "              resize_height=64, resize_width=64,\n",
        "              crop=True):\n",
        "  image = load_webp(image_path)\n",
        "  return transform(image, input_height, input_width,\n",
        "                   resize_height, resize_width, crop)\n",
        "\n",
        "def load_webp(img_path):\n",
        "    im = Image.open(img_path)\n",
        "    return np.asarray(im)\n",
        "\n",
        "\n",
        "def merge(images, size):\n",
        "  h, w = images.shape[1], images.shape[2]\n",
        "  if (images.shape[3] in (3,4)):\n",
        "    c = images.shape[3]\n",
        "    img = np.zeros((h * size[0], w * size[1], c))\n",
        "    for idx, image in enumerate(images):\n",
        "      i = idx % size[1]\n",
        "      j = idx // size[1]\n",
        "      img[j * h:j * h + h, i * w:i * w + w, :] = image\n",
        "    return img\n",
        "  elif images.shape[3]==1:\n",
        "    img = np.zeros((h * size[0], w * size[1]))\n",
        "    for idx, image in enumerate(images):\n",
        "      i = idx % size[1]\n",
        "      j = idx // size[1]\n",
        "      img[j * h:j * h + h, i * w:i * w + w] = image[:,:,0]\n",
        "    return img\n",
        "  else:\n",
        "    raise ValueError('in merge(images,size) images parameter '\n",
        "                     'must have dimensions: HxW or HxWx3 or HxWx4')\n",
        "\n",
        "\n",
        "def center_crop(x, crop_h, crop_w,\n",
        "                resize_h=64, resize_w=64):\n",
        "  if crop_w is None:\n",
        "    crop_w = crop_h\n",
        "  h, w = x.shape[:2]\n",
        "  j = int(round((h - crop_h)/2.))\n",
        "  i = int(round((w - crop_w)/2.))\n",
        "  return scipy.misc.imresize(\n",
        "      x[j:j+crop_h, i:i+crop_w], [resize_h, resize_w])\n",
        "\n",
        "def transform(image, input_height, input_width,\n",
        "              resize_height=64, resize_width=64, crop=True):\n",
        "  if crop:\n",
        "    cropped_image = center_crop(\n",
        "      image, input_height, input_width,\n",
        "      resize_height, resize_width)\n",
        "  else:\n",
        "    cropped_image = scipy.misc.imresize(image, [resize_height, resize_width])\n",
        "  if len(cropped_image.shape) != 3: #In case of binary mask with no channels:\n",
        "    cropped_image = np.expand_dims(cropped_image, -1)\n",
        "  return np.array(cropped_image)[:, :, :3]/127.5 - 1.\n",
        "\n",
        "def inverse_transform(images):\n",
        "  return (images+1.)/2.\n",
        "\n",
        "def image_manifold_size(num_images):\n",
        "  manifold_h = int(np.floor(np.sqrt(num_images)))\n",
        "  manifold_w = int(np.ceil(np.sqrt(num_images)))\n",
        "\n",
        "  assert manifold_h * manifold_w == num_images\n",
        "  return manifold_h, manifold_w\n",
        "\n",
        "def to_bool(value):\n",
        "    \"\"\"\n",
        "       Converts 'something' to boolean. Raises exception for invalid formats\n",
        "           Possible True  values: 1, True, \"1\", \"TRue\", \"yes\", \"y\", \"t\"\n",
        "           Possible False values: 0, False, None, [], {}, \"\", \"0\", \"faLse\", \"no\", \"n\", \"f\", 0.0, ...\n",
        "    \"\"\"\n",
        "    if str(value).lower() == \"true\": return True\n",
        "    if str(value).lower() == \"false\": return False\n",
        "    raise Exception('Invalid value for boolean conversion: ' + str(value))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "fatal: destination path 'binvox-rw-py' already exists and is not an empty directory.\n",
            "*\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "T47vQ79WEHVQ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from __future__ import division\n",
        "import os\n",
        "import sys\n",
        "from glob import glob\n",
        "import json\n",
        "import shutil\n",
        "import glob\n",
        "\n",
        "\n",
        "\n",
        "#----------------------------------------------------------------------------\n",
        "\n",
        "class HoloGAN(object):\n",
        "  def __init__(self, sess, input_height=108, input_width=108, crop=True,\n",
        "         output_height=64, output_width=64,\n",
        "         gf_dim=64, df_dim=64,\n",
        "         c_dim=3, dataset_name='lsun',\n",
        "         input_fname_pattern='*.webp'):\n",
        "\n",
        "    self.sess = sess\n",
        "    self.crop = crop\n",
        "\n",
        "    self.input_height = input_height\n",
        "    self.input_width = input_width\n",
        "    self.output_height = output_height\n",
        "    self.output_width = output_width\n",
        "\n",
        "    self.gf_dim = gf_dim\n",
        "    self.df_dim = df_dim\n",
        "    self.c_dim = c_dim\n",
        "\n",
        "    self.dataset_name = dataset_name\n",
        "    self.input_fname_pattern = input_fname_pattern\n",
        "    self.data = glob.glob(os.path.join(IMAGE_PATH, self.input_fname_pattern))\n",
        "    self.checkpoint_dir = LOGDIR\n",
        "\n",
        "  def build(self, build_func_name):\n",
        "      build_func = eval(\"self.\" + build_func_name)\n",
        "      build_func()\n",
        "\n",
        "  def build_HoloGAN(self):\n",
        "    self.view_in = tf.placeholder(tf.float32, [None, 6], name='view_in')\n",
        "    self.inputs = tf.placeholder(tf.float32, [None, self.output_height, self.output_width, self.c_dim], name='real_images')\n",
        "    self.z = tf.placeholder(tf.float32, [None, cfg['z_dim']], name='z')\n",
        "    inputs = self.inputs\n",
        "\n",
        "    gen_func = eval(\"self.\" + (cfg['generator']))\n",
        "    dis_func = eval(\"self.\" + (cfg['discriminator']))\n",
        "    self.gen_view_func = eval(cfg['view_func'])\n",
        "\n",
        "    self.G = gen_func(self.z, self.view_in)\n",
        "\n",
        "    if str.lower(str(cfg[\"style_disc\"])) == \"true\":\n",
        "        print(\"Style Disc\")\n",
        "        self.D, self.D_logits, _, self.d_h1_r, self.d_h2_r, self.d_h3_r, self.d_h4_r = dis_func(inputs, cont_dim=cfg['z_dim'], reuse=False)\n",
        "        self.D_, self.D_logits_, self.Q_c_given_x, self.d_h1_f, self.d_h2_f, self.d_h3_f, self.d_h4_f = dis_func(self.G, cont_dim=cfg['z_dim'], reuse=True)\n",
        "\n",
        "        self.d_h1_loss = cfg[\"DStyle_lambda\"] * (\n",
        "                    tf.reduce_mean(sigmoid_cross_entropy_with_logits(self.d_h1_r, tf.ones_like(self.d_h1_r))) \\\n",
        "                    + tf.reduce_mean(sigmoid_cross_entropy_with_logits(self.d_h1_f, tf.zeros_like(self.d_h1_f))))\n",
        "        self.d_h2_loss = cfg[\"DStyle_lambda\"] * (\n",
        "                    tf.reduce_mean(sigmoid_cross_entropy_with_logits(self.d_h2_r, tf.ones_like(self.d_h2_r))) \\\n",
        "                    + tf.reduce_mean(sigmoid_cross_entropy_with_logits(self.d_h2_f, tf.zeros_like(self.d_h2_f))))\n",
        "        self.d_h3_loss = cfg[\"DStyle_lambda\"] * (\n",
        "                    tf.reduce_mean(sigmoid_cross_entropy_with_logits(self.d_h3_r, tf.ones_like(self.d_h3_r))) \\\n",
        "                    + tf.reduce_mean(sigmoid_cross_entropy_with_logits(self.d_h3_f, tf.zeros_like(self.d_h3_f))))\n",
        "        self.d_h4_loss = cfg[\"DStyle_lambda\"] * (\n",
        "                    tf.reduce_mean(sigmoid_cross_entropy_with_logits(self.d_h4_r, tf.ones_like(self.d_h4_r))) \\\n",
        "                    + tf.reduce_mean(sigmoid_cross_entropy_with_logits(self.d_h4_f, tf.zeros_like(self.d_h4_f))))\n",
        "    else:\n",
        "        self.D, self.D_logits, _ = dis_func(inputs, cont_dim=cfg['z_dim'], reuse=False)\n",
        "        self.D_, self.D_logits_, self.Q_c_given_x = dis_func(self.G, cont_dim=cfg['z_dim'], reuse=True)\n",
        "\n",
        "\n",
        "    self.d_loss_real = tf.reduce_mean(sigmoid_cross_entropy_with_logits(self.D_logits, tf.ones_like(self.D)))\n",
        "    self.d_loss_fake = tf.reduce_mean(sigmoid_cross_entropy_with_logits(self.D_logits_, tf.zeros_like(self.D_)))\n",
        "    self.d_loss = self.d_loss_real + self.d_loss_fake\n",
        "    self.g_loss = tf.reduce_mean(sigmoid_cross_entropy_with_logits(self.D_logits_, tf.ones_like(self.D_)))\n",
        "\n",
        "\n",
        "    if str.lower(str(cfg[\"style_disc\"])) == \"true\":\n",
        "        print(\"Style disc\")\n",
        "        self.d_loss = self.d_loss + self.d_h1_loss + self.d_h2_loss + self.d_h3_loss + self.d_h4_loss\n",
        "    #====================================================================================================================\n",
        "    #Identity loss\n",
        "\n",
        "    self.q_loss = cfg[\"lambda_latent\"] * tf.reduce_mean(tf.square(self.Q_c_given_x - self.z))\n",
        "    self.d_loss = self.d_loss + self.q_loss\n",
        "    self.g_loss = self.g_loss + self.q_loss\n",
        "\n",
        "\n",
        "    self.d_loss_real_sum = scalar_summary(\"d_loss_real\", self.d_loss_real)\n",
        "    self.d_loss_fake_sum = scalar_summary(\"d_loss_fake\", self.d_loss_fake)\n",
        "    self.g_loss_sum = scalar_summary(\"g_loss\", self.g_loss)\n",
        "    self.d_loss_sum = scalar_summary(\"d_loss\", self.d_loss)\n",
        "\n",
        "    t_vars = tf.trainable_variables()\n",
        "\n",
        "    self.d_vars = [var for var in t_vars if 'd_' in var.name]\n",
        "    self.g_vars = [var for var in t_vars if 'g_' in var.name]\n",
        "\n",
        "    self.saver = tf.train.Saver()\n",
        "\n",
        "  def train_HoloGAN(self, config):\n",
        "      self.d_lr_in = tf.placeholder(tf.float32, None, name='d_eta')\n",
        "      self.g_lr_in = tf.placeholder(tf.float32, None, name='d_eta')\n",
        "\n",
        "      d_optim = tf.train.AdamOptimizer(cfg['d_eta'], beta1=cfg['beta1'], beta2=cfg['beta2']).minimize(self.d_loss, var_list=self.d_vars)\n",
        "      g_optim = tf.train.AdamOptimizer(cfg['g_eta'], beta1=cfg['beta1'], beta2=cfg['beta2']).minimize(self.g_loss, var_list=self.g_vars)\n",
        "\n",
        "      tf.global_variables_initializer().run()\n",
        "\n",
        "      shutil.copyfile(sys.argv[1], os.path.join(LOGDIR, 'config.json'))\n",
        "      self.g_sum = merge_summary([self.d_loss_fake_sum, self.g_loss_sum])\n",
        "      self.d_sum = merge_summary([self.d_loss_real_sum, self.d_loss_sum])\n",
        "      self.writer = SummaryWriter(LOGDIR, self.sess.graph)\n",
        "\n",
        "      # Sample noise Z and view parameters to test during training\n",
        "      sample_z = self.sampling_Z(cfg['z_dim'], str(cfg['sample_z']))\n",
        "      sample_view = self.gen_view_func(cfg['batch_size'],\n",
        "                                       cfg['ele_low'], cfg['ele_high'],\n",
        "                                       cfg['azi_low'], cfg['azi_high'],\n",
        "                                       cfg['scale_low'], cfg['scale_high'],\n",
        "                                       cfg['x_low'], cfg['x_high'],\n",
        "                                       cfg['y_low'], cfg['y_high'],\n",
        "                                       cfg['z_low'], cfg['z_high'],\n",
        "                                       with_translation=False,\n",
        "                                       with_scale=to_bool(str(cfg['with_translation'])))\n",
        "      sample_files = self.data[0:cfg['batch_size']]\n",
        "\n",
        "      if config.dataset == \"cats\" or config.dataset == \"cars\":\n",
        "          sample_images = [get_image(sample_file,\n",
        "                                    input_height=self.input_height,\n",
        "                                    input_width=self.input_width,\n",
        "                                    resize_height=self.output_height,\n",
        "                                    resize_width=self.output_width,\n",
        "                                    crop=False) for sample_file in sample_files]\n",
        "      else:\n",
        "          sample_images = [get_image(sample_file,\n",
        "                                    input_height=self.input_height,\n",
        "                                    input_width=self.input_width,\n",
        "                                    resize_height=self.output_height,\n",
        "                                    resize_width=self.output_width,\n",
        "                                    crop=True) for sample_file in sample_files]\n",
        "\n",
        "      counter = 1\n",
        "      start_time = time.time()\n",
        "      could_load, checkpoint_counter = self.load(self.checkpoint_dir)\n",
        "      if could_load:\n",
        "          counter = checkpoint_counter\n",
        "          print(\" [*] Load SUCCESS\")\n",
        "      else:\n",
        "          print(\" [!] Load failed...\")\n",
        "\n",
        "      self.data = glob.glob(os.path.join(IMAGE_PATH, self.input_fname_pattern))\n",
        "      d_lr = cfg['d_eta']\n",
        "      g_lr = cfg['g_eta']\n",
        "      for epoch in range(cfg['max_epochs']):\n",
        "          d_lr = d_lr if epoch < cfg['epoch_step'] else d_lr * (cfg['max_epochs'] - epoch) / (cfg['max_epochs'] - cfg['epoch_step'])\n",
        "          g_lr = g_lr if epoch < cfg['epoch_step'] else g_lr * (cfg['max_epochs'] - epoch) / (cfg['max_epochs'] - cfg['epoch_step'])\n",
        "\n",
        "          random.shuffle(self.data)\n",
        "          batch_idxs = min(len(self.data), config.train_size) // cfg['batch_size']\n",
        "\n",
        "          for idx in range(0, batch_idxs):\n",
        "              batch_files = self.data[idx * cfg['batch_size']:(idx + 1) * cfg['batch_size']]\n",
        "              if config.dataset == \"cats\" or config.dataset == \"cars\":\n",
        "                  batch_images = [get_image(batch_file,\n",
        "                                    input_height=self.input_height,\n",
        "                                    input_width=self.input_width,\n",
        "                                    resize_height=self.output_height,\n",
        "                                    resize_width=self.output_width,\n",
        "                                    crop=False) for batch_file in batch_files]\n",
        "              else:\n",
        "                  batch_images = [get_image(batch_file,\n",
        "                                    input_height=self.input_height,\n",
        "                                    input_width=self.input_width,\n",
        "                                    resize_height=self.output_height,\n",
        "                                    resize_width=self.output_width,\n",
        "                                    crop=self.crop) for batch_file in batch_files]\n",
        "\n",
        "              batch_z = self.sampling_Z(cfg['z_dim'], str(cfg['sample_z']))\n",
        "              batch_view = self.gen_view_func(cfg['batch_size'],\n",
        "                                       cfg['ele_low'], cfg['ele_high'],\n",
        "                                       cfg['azi_low'], cfg['azi_high'],\n",
        "                                       cfg['scale_low'], cfg['scale_high'],\n",
        "                                       cfg['x_low'], cfg['x_high'],\n",
        "                                       cfg['y_low'], cfg['y_high'],\n",
        "                                       cfg['z_low'], cfg['z_high'],\n",
        "                                       with_translation=False,\n",
        "                                       with_scale=to_bool(str(cfg['with_translation'])))\n",
        "\n",
        "              feed = {self.inputs: batch_images,\n",
        "                      self.z: batch_z,\n",
        "                      self.view_in: batch_view,\n",
        "                      self.d_lr_in: d_lr,\n",
        "                      self.g_lr_in: g_lr}\n",
        "              # Update D network\n",
        "              _, summary_str = self.sess.run([d_optim, self.d_sum],feed_dict=feed)\n",
        "              self.writer.add_summary(summary_str, counter)\n",
        "              # Update G network\n",
        "              _, summary_str = self.sess.run([g_optim, self.g_sum], feed_dict=feed)\n",
        "              self.writer.add_summary(summary_str, counter)\n",
        "              # Run g_optim twice\n",
        "              _, summary_str = self.sess.run([g_optim, self.g_sum],  feed_dict=feed)\n",
        "              self.writer.add_summary(summary_str, counter)\n",
        "\n",
        "              errD_fake = self.d_loss_fake.eval(feed)\n",
        "              errD_real = self.d_loss_real.eval(feed)\n",
        "              errG = self.g_loss.eval(feed)\n",
        "              errQ = self.q_loss.eval(feed)\n",
        "\n",
        "              counter += 1\n",
        "              print(\"Epoch: [%2d] [%4d/%4d] time: %4.4f, d_loss: %.8f, g_loss: %.8f, q_loss: %.8f\" \\\n",
        "                    % (epoch, idx, batch_idxs,\n",
        "                       time.time() - start_time, errD_fake + errD_real, errG, errQ))\n",
        "\n",
        "              if np.mod(counter, 1000) == 1:\n",
        "                  self.save(LOGDIR, counter)\n",
        "                  feed_eval = {self.inputs: sample_images,\n",
        "                               self.z: sample_z,\n",
        "                               self.view_in: sample_view,\n",
        "                               self.d_lr_in: d_lr,\n",
        "                               self.g_lr_in: g_lr}\n",
        "                  samples, d_loss, g_loss = self.sess.run(\n",
        "                      [self.G, self.d_loss, self.g_loss],\n",
        "                      feed_dict=feed_eval)\n",
        "                  ren_img = inverse_transform(samples)\n",
        "                  ren_img = np.clip(255 * ren_img, 0, 255).astype(np.uint8)\n",
        "                  try:\n",
        "                      scipy.misc.imsave(\n",
        "                          os.path.join(OUTPUT_DIR, \"{0}_GAN.png\".format(counter)),\n",
        "                          merge(ren_img, [cfg['batch_size'] // 4, 4]))\n",
        "                      print(\"[Sample] d_loss: %.8f, g_loss: %.8f\" % (d_loss, g_loss))\n",
        "                  except:\n",
        "                      scipy.misc.imsave(\n",
        "                          os.path.join(OUTPUT_DIR, \"{0}_GAN.png\".format(counter)),\n",
        "                          ren_img[0])\n",
        "                      print(\"[Sample] d_loss: %.8f, g_loss: %.8f\" % (d_loss, g_loss))\n",
        "\n",
        "  def sample_HoloGAN(self, config):\n",
        "      could_load, checkpoint_counter = self.load(self.checkpoint_dir)\n",
        "      if could_load:\n",
        "          counter = checkpoint_counter\n",
        "          print(\" [*] Load SUCCESS\")\n",
        "      else:\n",
        "          print(\" [!] Load failed...\")\n",
        "          return\n",
        "      SAMPLE_DIR = os.path.join(OUTPUT_DIR, \"samples\")\n",
        "      if not os.path.exists(SAMPLE_DIR):\n",
        "          os.makedirs(SAMPLE_DIR)\n",
        "      sample_z = self.sampling_Z(cfg['z_dim'], str(cfg['sample_z']))\n",
        "      if config.rotate_azimuth:\n",
        "          low  = cfg['azi_low']\n",
        "          high = cfg['azi_high']\n",
        "          step = 10\n",
        "      elif config.rotate_elevation:\n",
        "          low  = cfg['ele_low']\n",
        "          high = cfg['ele_high']\n",
        "          step = 5\n",
        "      else:\n",
        "          low  = 0\n",
        "          high = 10\n",
        "          step = 1\n",
        "\n",
        "      for i in range(low, high, step):\n",
        "          if config.rotate_azimuth:\n",
        "              sample_view = np.tile(\n",
        "                  np.array([i * math.pi / 180.0, 0 * math.pi / 180.0, 1.0, 0, 0, 0]), (cfg['batch_size'], 1))\n",
        "          elif config.rotate_azimuth:\n",
        "              sample_view = np.tile(\n",
        "                  np.array([270 * math.pi / 180.0, (90 - i) * math.pi / 180.0, 1.0, 0, 0, 0]), (cfg['batch_size'], 1))\n",
        "          else:\n",
        "              sample_view = self.gen_view_func(cfg['batch_size'],\n",
        "                                               cfg['ele_low'], cfg['ele_high'],\n",
        "                                               cfg['azi_low'], cfg['azi_high'],\n",
        "                                               cfg['scale_low'], cfg['scale_high'],\n",
        "                                               cfg['x_low'], cfg['x_high'],\n",
        "                                               cfg['y_low'], cfg['y_high'],\n",
        "                                               cfg['z_low'], cfg['z_high'],\n",
        "                                               with_translation=False,\n",
        "                                               with_scale=to_bool(str(cfg['with_translation'])))\n",
        "\n",
        "          feed_eval = {self.z: sample_z,\n",
        "                       self.view_in: sample_view}\n",
        "\n",
        "          samples = self.sess.run(self.G, feed_dict=feed_eval)\n",
        "          ren_img = inverse_transform(samples)\n",
        "          ren_img = np.clip(255 * ren_img, 0, 255).astype(np.uint8)\n",
        "          try:\n",
        "              scipy.misc.imsave(\n",
        "                  os.path.join(SAMPLE_DIR, \"{0}_samples_{1}.png\".format(counter, i)),\n",
        "                  merge(ren_img, [cfg['batch_size'] // 4, 4]))\n",
        "          except:\n",
        "              scipy.misc.imsave(\n",
        "                  os.path.join(SAMPLE_DIR, \"{0}_samples_{1}.png\".format(counter, i)),\n",
        "                  ren_img[0])\n",
        "\n",
        "#=======================================================================================================================\n",
        "\n",
        "  def sampling_Z(self, z_dim, type=\"uniform\"):\n",
        "      if str.lower(type) == \"uniform\":\n",
        "          return np.random.uniform(-1., 1., (cfg['batch_size'], z_dim))\n",
        "      else:\n",
        "          return np.random.normal(0, 1, (cfg['batch_size'], z_dim))\n",
        "\n",
        "  def linear_classifier(self, features, scope = \"lin_class\", stddev=0.02, reuse=False):\n",
        "      with tf.variable_scope(scope) as sc:\n",
        "          w = tf.get_variable('w', [features.get_shape()[-1], 1],\n",
        "                              initializer=tf.random_normal_initializer(stddev=stddev))\n",
        "          b = tf.get_variable('biases', 1, initializer=tf.constant_initializer(0.0))\n",
        "          logits = tf.matmul(features, w) + b\n",
        "          return   tf.nn.sigmoid(logits), logits\n",
        "\n",
        "  def z_mapping_function(self, z, output_channel, scope='z_mapping', act=\"relu\", stddev=0.02):\n",
        "      with tf.variable_scope(scope) as sc:\n",
        "          w = tf.get_variable('w', [z.get_shape()[-1], output_channel * 2],\n",
        "                              initializer=tf.random_normal_initializer(stddev=stddev))\n",
        "          b = tf.get_variable('biases', output_channel * 2, initializer=tf.constant_initializer(0.0))\n",
        "          if act == \"relu\":\n",
        "              out = tf.nn.relu(tf.matmul(z, w) + b)\n",
        "          else:\n",
        "              out = lrelu(tf.matmul(z, w) + b)\n",
        "          return out[:, :output_channel], out[:, output_channel:]\n",
        "\n",
        "#=======================================================================================================================\n",
        "  def discriminator_IN(self, image,  cont_dim, reuse=False):\n",
        "      if str(cfg[\"add_D_noise\"]) == \"true\":\n",
        "          image = image + tf.random_normal(tf.shape(image), stddev=0.02)\n",
        "\n",
        "      with tf.variable_scope(\"discriminator\") as scope:\n",
        "          if reuse:\n",
        "              scope.reuse_variables()\n",
        "\n",
        "          h0 = lrelu(conv2d(image, self.df_dim, name='d_h0_conv'))\n",
        "          h1 = lrelu(instance_norm(conv2d_specNorm(h0, self.df_dim * 2, name='d_h1_conv'),'d_in1'))\n",
        "          h2 = lrelu(instance_norm(conv2d_specNorm(h1, self.df_dim * 4, name='d_h2_conv'),'d_in2'))\n",
        "          h3 = lrelu(instance_norm(conv2d_specNorm(h2, self.df_dim * 8, name='d_h3_conv'),'d_in3'))\n",
        "\n",
        "          #Returning logits to determine whether the images are real or fake\n",
        "          h4 = linear(slim.flatten(h3), 1, 'd_h4_lin')\n",
        "\n",
        "          # Recognition network for latent variables has an additional layer\n",
        "          encoder = lrelu((linear(slim.flatten(h3), 128, 'd_latent')))\n",
        "          cont_vars = linear(encoder, cont_dim, \"d_latent_prediction\")\n",
        "\n",
        "          return tf.nn.sigmoid(h4), h4, tf.nn.tanh(cont_vars)\n",
        "\n",
        "  def discriminator_IN_style_res128(self, image,  cont_dim, reuse=False):\n",
        "      batch_size = tf.shape(image)[0]\n",
        "      if str(cfg[\"add_D_noise\"]) == \"true\":\n",
        "          image = image + tf.random_normal(tf.shape(image), stddev=0.02)\n",
        "\n",
        "      with tf.variable_scope(\"discriminator\") as scope:\n",
        "          if reuse:\n",
        "              scope.reuse_variables()\n",
        "\n",
        "          h0 = lrelu(conv2d(image, self.df_dim, name='d_h0_conv'))\n",
        "\n",
        "          h1 = conv2d_specNorm(h0, self.df_dim * 2, name='d_h1_conv')\n",
        "          h1, h1_mean, h1_var = instance_norm(h1, 'd_in1', True)\n",
        "          h1_mean = tf.reshape(h1_mean, (batch_size, self.df_dim * 2))\n",
        "          h1_var = tf.reshape(h1_var, (batch_size, self.df_dim * 2))\n",
        "          d_h1_style = tf.concat([h1_mean, h1_var], 0)\n",
        "          d_h1, d_h1_logits = self.linear_classifier(d_h1_style, \"d_h1_class\")\n",
        "          h1 = lrelu(h1)\n",
        "\n",
        "          h2 = conv2d_specNorm(h1, self.df_dim * 4, name='d_h2_conv')\n",
        "          h2, h2_mean, h2_var = instance_norm(h2, 'd_in2', True)\n",
        "          h2_mean = tf.reshape(h2_mean, (batch_size, self.df_dim * 4))\n",
        "          h2_var = tf.reshape(h2_var, (batch_size, self.df_dim * 4))\n",
        "          d_h2_style = tf.concat([h2_mean, h2_var], 0)\n",
        "          d_h2, d_h2_logits = self.linear_classifier(d_h2_style, \"d_h2_class\")\n",
        "          h2 = lrelu(h2)\n",
        "\n",
        "          h3 = conv2d_specNorm(h2, self.df_dim * 8, name='d_h3_conv')\n",
        "          h3, h3_mean, h3_var = instance_norm(h3, 'd_in3', True)\n",
        "          h3_mean = tf.reshape(h3_mean, (batch_size, self.df_dim * 8))\n",
        "          h3_var = tf.reshape(h3_var, (batch_size, self.df_dim * 8))\n",
        "          d_h3_style = tf.concat([h3_mean, h3_var], 0)\n",
        "          d_h3, d_h3_logits = self.linear_classifier(d_h3_style, \"d_h3_class\")\n",
        "          h3 = lrelu(h3)\n",
        "\n",
        "          h4 = conv2d_specNorm(h3, self.df_dim * 16, name='d_h4_conv')\n",
        "          h4, h4_mean, h4_var = instance_norm(h4, 'd_in4', True)\n",
        "          h4_mean = tf.reshape(h4_mean, (batch_size, self.df_dim * 16))\n",
        "          h4_var = tf.reshape(h4_var, (batch_size, self.df_dim * 16))\n",
        "          d_h4_style = tf.concat([h4_mean, h4_var], 0)\n",
        "          d_h4, d_h4_logits = self.linear_classifier(d_h4_style, \"d_h4_class\")\n",
        "          h4 = lrelu(h4)\n",
        "\n",
        "          #Returning logits to determine whether the images are real or fake\n",
        "          h5 = linear(slim.flatten(h4), 1, 'd_h5_lin')\n",
        "\n",
        "          # Recognition network for latent variables has an additional layer\n",
        "          encoder = lrelu((linear(slim.flatten(h4), 128, 'd_latent')))\n",
        "          cont_vars = linear(encoder, cont_dim, \"d_latent_prediction\")\n",
        "\n",
        "          return tf.nn.sigmoid(h5), h5, tf.nn.tanh(cont_vars), d_h1_logits, d_h2_logits, d_h3_logits, d_h4_logits\n",
        "\n",
        "  def generator_AdaIN(self, z, view_in, reuse=False):\n",
        "      batch_size = tf.shape(z)[0]\n",
        "      s_h, s_w, s_d = 64, 64, 64\n",
        "      s_h2, s_w2, s_d2 = conv_out_size_same(s_h, 2), conv_out_size_same(s_w, 2), conv_out_size_same(s_d, 2)\n",
        "      s_h4, s_w4, s_d4 = conv_out_size_same(s_h2, 2), conv_out_size_same(s_w2, 2), conv_out_size_same(s_d2, 2)\n",
        "      s_h8, s_w8, s_d8 = conv_out_size_same(s_h4, 2), conv_out_size_same(s_w4, 2), conv_out_size_same(s_d4, 2)\n",
        "      s_h16, s_w16, s_d16 = conv_out_size_same(s_h8, 2), conv_out_size_same(s_w8, 2), conv_out_size_same(s_d8, 2)\n",
        "\n",
        "      with tf.variable_scope(\"generator\") as scope:\n",
        "          if reuse:\n",
        "              scope.reuse_variables()\n",
        "          #A learnt constant \"template\"\n",
        "          with tf.variable_scope('g_w_constant'):\n",
        "              w = tf.get_variable('w', [s_h16, s_w16, s_d16, self.gf_dim * 8], initializer=tf.random_normal_initializer(stddev=0.02))\n",
        "              w_tile = tf.tile(tf.expand_dims(w, 0), (batch_size, 1, 1, 1, 1))\n",
        "              s0, b0 = self.z_mapping_function(z, self.gf_dim * 8, 'g_z0')\n",
        "              h0 = AdaIn(w_tile, s0, b0)\n",
        "              h0 = tf.nn.relu(h0)\n",
        "\n",
        "          h1= deconv3d(h0, [batch_size, s_h8, s_w8, s_d8, self.gf_dim * 2], k_h=3, k_d=3, k_w=3, name='g_h1')\n",
        "          s1, b1 = self.z_mapping_function(z, self.gf_dim * 2, 'g_z1')\n",
        "          h1 = AdaIn(h1, s1, b1)\n",
        "          h1 = tf.nn.relu(h1)\n",
        "\n",
        "          h2 = deconv3d(h1, [batch_size, s_h4, s_w4, s_d4, self.gf_dim * 1], k_h=3, k_d=3, k_w=3, name='g_h2')\n",
        "          s2, b2 = self.z_mapping_function(z, self.gf_dim * 1, 'g_z2')\n",
        "          h2 = AdaIn(h2, s2, b2)\n",
        "          h2 = tf.nn.relu(h2)\n",
        "\n",
        "          #=============================================================================================================\n",
        "          h2_rotated = tf_3D_transform(h2, view_in, 16, 16)\n",
        "          h2_rotated = transform_voxel_to_match_image(h2_rotated)\n",
        "          #=============================================================================================================\n",
        "          # Collapsing depth dimension\n",
        "          h2_2d = tf.reshape(h2_rotated, [batch_size, s_h4, s_w4, 16 * self.gf_dim])\n",
        "          # 1X1 convolution\n",
        "          h3 = deconv2d(h2_2d, [batch_size, s_h4, s_w4, self.gf_dim * 16], k_h=1, k_w=1, d_h=1, d_w=1, name='g_h3')\n",
        "          h3 = tf.nn.relu(h3)\n",
        "          #=============================================================================================================\n",
        "\n",
        "          h4  = deconv2d(h3, [batch_size, s_h2, s_w2, self.gf_dim * 4], k_h=4, k_w=4, name='g_h4')\n",
        "          s4, b4 = self.z_mapping_function(z, self.gf_dim * 4, 'g_z4')\n",
        "          h4  = AdaIn(h4, s4, b4)\n",
        "          h4  = tf.nn.relu(h4)\n",
        "\n",
        "          h5 = deconv2d(h4, [batch_size, s_h, s_w, self.gf_dim], k_h=4, k_w=4, name='g_h5')\n",
        "          s5, b5 = self.z_mapping_function(z, self.gf_dim, 'g_z5')\n",
        "          h5 = AdaIn(h5, s5, b5)\n",
        "          h5 = tf.nn.relu(h5)\n",
        "\n",
        "          h6 = deconv2d(h5, [batch_size, s_h, s_w, self.c_dim], k_h=4, k_w=4, d_h=1, d_w=1, name='g_h6')\n",
        "\n",
        "          output = tf.nn.tanh(h6, name=\"output\")\n",
        "          return output\n",
        "\n",
        "  def generator_AdaIN_res128(self, z, view_in, reuse=False):\n",
        "      batch_size = tf.shape(z)[0]\n",
        "      s_h, s_w, s_d = 64, 64, 64\n",
        "      s_h2, s_w2, s_d2 = conv_out_size_same(s_h, 2), conv_out_size_same(s_w, 2), conv_out_size_same(s_d, 2)\n",
        "      s_h4, s_w4, s_d4 = conv_out_size_same(s_h2, 2), conv_out_size_same(s_w2, 2), conv_out_size_same(s_d2, 2)\n",
        "      s_h8, s_w8, s_d8 = conv_out_size_same(s_h4, 2), conv_out_size_same(s_w4, 2), conv_out_size_same(s_d4, 2)\n",
        "      s_h16, s_w16, s_d16 = conv_out_size_same(s_h8, 2), conv_out_size_same(s_w8, 2), conv_out_size_same(s_d8, 2)\n",
        "\n",
        "      with tf.variable_scope(\"generator\") as scope:\n",
        "          if reuse:\n",
        "              scope.reuse_variables()\n",
        "          #A learnt constant \"template\"\n",
        "          with tf.variable_scope('g_w_constant'):\n",
        "              w = tf.get_variable('w', [s_h16, s_w16, s_d16, self.gf_dim * 8], initializer=tf.random_normal_initializer(stddev=0.02))\n",
        "              w_tile = tf.tile(tf.expand_dims(w, 0), (batch_size, 1, 1, 1, 1)) #Repeat the learnt constant features to make a batch\n",
        "              s0, b0 = self.z_mapping_function(z, self.gf_dim * 8, 'g_z0')\n",
        "              h0 = AdaIn(w_tile, s0, b0)\n",
        "              h0 = lrelu(h0)\n",
        "\n",
        "          h1= deconv3d(h0, [batch_size, s_h8, s_w8, s_d8, self.gf_dim * 4], k_h=3, k_w=3, k_d=3, name='g_h1')\n",
        "          s1, b1 = self.z_mapping_function(z, self.gf_dim * 4, 'g_z1')\n",
        "          h1 = AdaIn(h1, s1, b1)\n",
        "          h1 = lrelu(h1)\n",
        "\n",
        "          h2 = deconv3d(h1, [batch_size, s_h4, s_w4, s_d4, self.gf_dim * 2],  k_h=3, k_w=3, k_d=3, name='g_h2')\n",
        "          s2, b2 = self.z_mapping_function(z, self.gf_dim * 2, 'g_z2')\n",
        "          h2 = AdaIn(h2, s2, b2)\n",
        "          h2 = lrelu(h2)\n",
        "\n",
        "          #=============================================================================================================\n",
        "          h2_rotated = tf_3D_transform(h2, view_in, 16, 16)\n",
        "          h2_rotated = transform_voxel_to_match_image(h2_rotated)\n",
        "\n",
        "          h2_proj1 = deconv3d(h2_rotated, [batch_size, s_h4, s_w4, s_d4, self.gf_dim * 1], k_h=3, k_w=3, k_d=3, d_h=1, d_w=1, d_d=1, name='g_h2_proj1')\n",
        "          h2_proj1 = lrelu( h2_proj1)\n",
        "\n",
        "          h2_proj2 = deconv3d(h2_proj1, [batch_size, s_h4, s_w4, s_d4, self.gf_dim ], k_h=3, k_w=3, k_d=3, d_h=1, d_w=1, d_d=1,  name='g_h2_proj2')\n",
        "          h2_proj2 = lrelu( h2_proj2)\n",
        "          # =============================================================================================================\n",
        "          # Collapsing depth dimension\n",
        "          h2_2d = tf.reshape(h2_proj2, [batch_size, s_h4, s_w4, s_d4 * self.gf_dim])\n",
        "          # 1X1 convolution\n",
        "          h3 = deconv2d(h2_2d, [batch_size, s_h4, s_w4, self.gf_dim * 16 // 2], k_h=1, k_w=1, d_h=1, d_w=1, name='g_h3')\n",
        "          h3 = lrelu(h3)\n",
        "          # =============================================================================================================\n",
        "\n",
        "          h4  = deconv2d(h3, [batch_size, s_h2, s_w2, self.gf_dim * 4],  k_h=4, k_w=4, name='g_h4')\n",
        "          s4, b4 = self.z_mapping_function(z, self.gf_dim * 4, 'g_z4')\n",
        "          h4  = AdaIn(h4, s4, b4)\n",
        "          h4 = lrelu(h4)\n",
        "\n",
        "          h5 = deconv2d(h4, [batch_size, s_h, s_w, self.gf_dim], k_h=4, k_w=4, name='g_h5')\n",
        "          s5, b5 = self.z_mapping_function(z, self.gf_dim, 'g_z5')\n",
        "          h5 = AdaIn(h5, s5, b5)\n",
        "          h5 = lrelu(h5)\n",
        "\n",
        "          h6 = deconv2d(h5, [batch_size, s_h * 2, s_w * 2, self.gf_dim // 2], k_h=4, k_w=4, name='g_h6')\n",
        "          s6, b6 = self.z_mapping_function(z, self.gf_dim // 2, 'g_z6')\n",
        "          h6 = AdaIn(h6, s6, b6)\n",
        "          h6 = lrelu(h6)\n",
        "\n",
        "          h7 = deconv2d(h6, [batch_size, s_h * 2, s_w * 2, self.c_dim], k_h=4, k_w=4, d_h=1, d_w=1, name='g_h7')\n",
        "\n",
        "          output = tf.nn.tanh(h7, name=\"output\")\n",
        "          return output\n",
        "\n",
        "#=======================================================================================================================\n",
        "  @property\n",
        "  def model_dir(self):\n",
        "    return \"{}_{}_{}\".format(\n",
        "        self.dataset_name,\n",
        "        self.output_height, self.output_width)\n",
        "\n",
        "  def save(self, checkpoint_dir, step):\n",
        "    model_name = \"HoloGAN.model\"\n",
        "    checkpoint_dir = os.path.join(checkpoint_dir, self.model_dir)\n",
        "\n",
        "    if not os.path.exists(checkpoint_dir):\n",
        "      os.makedirs(checkpoint_dir)\n",
        "\n",
        "    self.saver.save(self.sess,\n",
        "            os.path.join(checkpoint_dir, model_name),\n",
        "            global_step=step)\n",
        "\n",
        "  def load(self, checkpoint_dir):\n",
        "    import re\n",
        "    print(\" [*] Reading checkpoints...\")\n",
        "    checkpoint_dir = os.path.join(checkpoint_dir, self.model_dir)\n",
        "\n",
        "    ckpt = tf.train.get_checkpoint_state(checkpoint_dir)\n",
        "    if ckpt and ckpt.model_checkpoint_path:\n",
        "      ckpt_name = os.path.basename(ckpt.model_checkpoint_path)\n",
        "      self.saver.restore(self.sess, os.path.join(checkpoint_dir, ckpt_name))\n",
        "      counter = int(next(re.finditer(\"(\\d+)(?!.*\\d)\",ckpt_name)).group(0))\n",
        "      print(\" [*] Success to read {}\".format(ckpt_name))\n",
        "      return True, counter\n",
        "    else:\n",
        "      print(\" [*] Failed to find a checkpoint\")\n",
        "      return False, 0\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9GaL_vncQNP7",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "cfg = {\n",
        "  \"image_path\":\"./celebA\",\n",
        "  \"gpu\":0,\n",
        "  \"batch_size\":32,\n",
        "  \"max_epochs\":50,\n",
        "  \"epoch_step\":25,\n",
        "  \"z_dim\":128,\n",
        "  \"d_eta\":0.0001,\n",
        "  \"g_eta\":0.0001,\n",
        "  \"beta1\":0.5,\n",
        "  \"beta2\":0.999,\n",
        "  \"discriminator\":\"discriminator_IN\",\n",
        "  \"generator\":\"generator_AdaIN\",\n",
        "  \"view_func\":\"generate_random_rotation_translation\",\n",
        "  \"train_func\":\"train_HoloGAN\",\n",
        "  \"build_func\":\"build_HoloGAN\",\n",
        "  \"style_disc\":\"false\",\n",
        "  \"sample_z\":\"uniform\",\n",
        "  \"add_D_noise\":\"false\",\n",
        "  \"DStyle_lambda\":1.0,\n",
        "\n",
        "  \"lambda_latent\":0.0,\n",
        "  \"ele_low\":70,\n",
        "  \"ele_high\":110,\n",
        "  \"azi_low\":220,\n",
        "  \"azi_high\":320,\n",
        "  \"scale_low\":1.0,\n",
        "  \"scale_high\":1.0,\n",
        "  \"x_low\":0,\n",
        "  \"x_high\":0,\n",
        "  \"y_low\":0,\n",
        "  \"y_high\":0,\n",
        "  \"z_low\":0,\n",
        "  \"z_high\":0,\n",
        "  \"with_translation\":\"false\",\n",
        "  \"with_scale\":\"false\",\n",
        "  \"output_dir\": \"./HoloGAN\"\n",
        "}"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qlLTYJf8ITMO",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import os\n",
        "import json\n",
        "import sys\n",
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "\n",
        "\n",
        "IMAGE_PATH = cfg['image_path']\n",
        "OUTPUT_DIR = cfg['output_dir']\n",
        "LOGDIR = os.path.join(OUTPUT_DIR, \"log\")\n",
        "\n",
        "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"{0}\".format(cfg['gpu'])\n",
        "\n",
        "\n",
        "flags = tf.app.flags\n",
        "\n",
        "flags.DEFINE_integer(\"input_height\", 108, \"The size of image to use (will be center cropped). [108] or [128] for celebA and lsun, [400] for chairs. Cats and Cars are already cropped\")\n",
        "flags.DEFINE_integer(\"input_width\", None, \"The size of image to use (will be center cropped). If None, same value as input_height [None]\")\n",
        "flags.DEFINE_integer(\"output_height\", 64, \"The size of the output images to produce 64 or 128\")\n",
        "flags.DEFINE_integer(\"output_width\", None, \"The size of the output images to produce. If None, same value as output_height [None]\")\n",
        "flags.DEFINE_string(\"dataset\", \"celebA\", \"The name of dataset [celebA, lsun, chairs, shoes, cars, cats]\")\n",
        "flags.DEFINE_string(\"input_fname_pattern\", \"*.jpg\", \"Glob pattern of filename of input images [*]\")\n",
        "flags.DEFINE_float(\"train_size\", np.inf, \"Number of images to train-Useful when only a subset of the dataset is needed to train the model\")\n",
        "flags.DEFINE_boolean(\"crop\", True, \"True for training, False for testing [False]\")\n",
        "flags.DEFINE_boolean(\"train\", True, \"True for training, False for testing [False]\")\n",
        "flags.DEFINE_boolean(\"rotate_azimuth\", False, \"Sample images with varying azimuth\")\n",
        "flags.DEFINE_boolean(\"rotate_elevation\", False, \"Sample images with varying elevation\")\n",
        "FLAGS = flags.FLAGS\n",
        "\n",
        "\n",
        "def main(_):\n",
        "  pp.pprint(flags.FLAGS.__flags)\n",
        "  if FLAGS.input_width is None:\n",
        "    FLAGS.input_width = FLAGS.input_height\n",
        "  if FLAGS.output_width is None:\n",
        "    FLAGS.output_width = FLAGS.output_height\n",
        "  if not os.path.exists(LOGDIR):\n",
        "    os.makedirs(LOGDIR)\n",
        "  if not os.path.exists(OUTPUT_DIR):\n",
        "    os.makedirs(OUTPUT_DIR)\n",
        "\n",
        "  run_config = tf.ConfigProto()\n",
        "  run_config.gpu_options.allow_growth=True\n",
        "  print(\"FLAGs \" + str(FLAGS.dataset))\n",
        "  with tf.Session(config=run_config) as sess:\n",
        "    model = HoloGAN(\n",
        "        sess,\n",
        "        input_width=FLAGS.input_width,\n",
        "        input_height=FLAGS.input_height,\n",
        "        output_width=FLAGS.output_width,\n",
        "        output_height=FLAGS.output_height,\n",
        "        dataset_name=FLAGS.dataset,\n",
        "        input_fname_pattern=FLAGS.input_fname_pattern,\n",
        "        crop=FLAGS.crop)\n",
        "\n",
        "    model.build(cfg['build_func'])\n",
        "\n",
        "    show_all_variables()\n",
        "\n",
        "    if FLAGS.train:\n",
        "        train_func = eval(\"model.\" + (cfg['train_func']))\n",
        "        train_func(FLAGS)\n",
        "    else:\n",
        "      if not model.load(LOGDIR)[0]:\n",
        "        raise Exception(\"[!] Train a model first, then run test mode\")\n",
        "      model.sample_HoloGAN(FLAGS)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uDDAx97KQO_F",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "tf.app.run()"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}