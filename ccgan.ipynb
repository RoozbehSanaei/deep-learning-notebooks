{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "ccgan.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyP1OnwIJISsYXJ8ZOAfg4FV",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/RoozbehSanaei/deep-learning-notebooks/blob/master/ccgan.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "laT8p38gs62u",
        "colab_type": "text"
      },
      "source": [
        "**[Semi-Supervised Learning with Context-Conditional Generative Adversarial Networks](https://openreview.net/forum?id=BJ--gPcxl)**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8tK7-sTrwrSr",
        "colab_type": "text"
      },
      "source": [
        "The purpose of CCgan is to augment a classifier with limited amount of data rather than generating images. classifier will be the discrimintator\n",
        "\n",
        "A generative\n",
        "model is trained to generate pixels within a missing hole, based on the context provided by surrounding parts of the image. These in-painted images are then used in an adversarial setting  to train a large discriminator model whose task is to determine if the image was real\n",
        "(from the unlabeled training set) or fake (an in-painted image). The realistic looking fake examples\n",
        "provided by the generative model cause the discriminator to learn features that generalize to the\n",
        "related task of classifying objects. \n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "75cyA1oyw7Cz",
        "colab_type": "text"
      },
      "source": [
        "![alt text](https://i.ibb.co/vmR9cY8/CCgan.png)\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EDvI33VTlR7_",
        "colab_type": "code",
        "outputId": "7e09b8c6-28cb-49dc-e723-5c76bb0e26b3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 386
        }
      },
      "source": [
        "!pip install git+https://www.github.com/keras-team/keras-contrib.git\n",
        "from __future__ import print_function, division\n",
        "\n",
        "from keras.datasets import mnist\n",
        "from keras_contrib.layers.normalization.instancenormalization import InstanceNormalization\n",
        "from keras.layers import Input, Dense, Reshape, Flatten, Dropout, multiply, GaussianNoise\n",
        "from keras.layers import BatchNormalization, Activation, Embedding, ZeroPadding2D\n",
        "from keras.layers import Concatenate\n",
        "from keras.layers.advanced_activations import LeakyReLU\n",
        "from keras.layers.convolutional import UpSampling2D, Conv2D\n",
        "from keras.models import Sequential, Model\n",
        "from keras.optimizers import Adam\n",
        "from keras import losses\n",
        "from keras.utils import to_categorical\n",
        "import keras.backend as K\n",
        "import scipy\n",
        "from PIL import Image\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "import numpy as np\n",
        "!mkdir images\n",
        "!mkdir saved_model"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting git+https://www.github.com/keras-team/keras-contrib.git\n",
            "  Cloning https://www.github.com/keras-team/keras-contrib.git to /tmp/pip-req-build-asa9esfs\n",
            "  Running command git clone -q https://www.github.com/keras-team/keras-contrib.git /tmp/pip-req-build-asa9esfs\n",
            "Requirement already satisfied: keras in /usr/local/lib/python3.6/dist-packages (from keras-contrib==2.0.8) (2.2.5)\n",
            "Requirement already satisfied: six>=1.9.0 in /usr/local/lib/python3.6/dist-packages (from keras->keras-contrib==2.0.8) (1.12.0)\n",
            "Requirement already satisfied: keras-preprocessing>=1.1.0 in /usr/local/lib/python3.6/dist-packages (from keras->keras-contrib==2.0.8) (1.1.0)\n",
            "Requirement already satisfied: keras-applications>=1.0.8 in /usr/local/lib/python3.6/dist-packages (from keras->keras-contrib==2.0.8) (1.0.8)\n",
            "Requirement already satisfied: h5py in /usr/local/lib/python3.6/dist-packages (from keras->keras-contrib==2.0.8) (2.8.0)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.6/dist-packages (from keras->keras-contrib==2.0.8) (3.13)\n",
            "Requirement already satisfied: numpy>=1.9.1 in /usr/local/lib/python3.6/dist-packages (from keras->keras-contrib==2.0.8) (1.17.5)\n",
            "Requirement already satisfied: scipy>=0.14 in /usr/local/lib/python3.6/dist-packages (from keras->keras-contrib==2.0.8) (1.4.1)\n",
            "Building wheels for collected packages: keras-contrib\n",
            "  Building wheel for keras-contrib (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for keras-contrib: filename=keras_contrib-2.0.8-cp36-none-any.whl size=101064 sha256=b0606d2d97ac11317e806edab9a1195931628132ad495e55be9d54ea420de468\n",
            "  Stored in directory: /tmp/pip-ephem-wheel-cache-_xx600z1/wheels/11/27/c8/4ed56de7b55f4f61244e2dc6ef3cdbaff2692527a2ce6502ba\n",
            "Successfully built keras-contrib\n",
            "Installing collected packages: keras-contrib\n",
            "Successfully installed keras-contrib-2.0.8\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<p style=\"color: red;\">\n",
              "The default version of TensorFlow in Colab will soon switch to TensorFlow 2.x.<br>\n",
              "We recommend you <a href=\"https://www.tensorflow.org/guide/migrate\" target=\"_blank\">upgrade</a> now \n",
              "or ensure your notebook will continue to use TensorFlow 1.x via the <code>%tensorflow_version 1.x</code> magic:\n",
              "<a href=\"https://colab.research.google.com/notebooks/tensorflow_version.ipynb\" target=\"_blank\">more info</a>.</p>\n"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ugwv3gjBlXEj",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class CCGAN():\n",
        "    def __init__(self):\n",
        "        self.img_rows = 32\n",
        "        self.img_cols = 32\n",
        "        self.channels = 1\n",
        "        self.img_shape = (self.img_rows, self.img_cols, self.channels)\n",
        "        self.mask_height = 10\n",
        "        self.mask_width = 10\n",
        "        self.num_classes = 10\n",
        "\n",
        "        # Number of filters in first layer of generator and discriminator\n",
        "        self.gf = 32\n",
        "        self.df = 32\n",
        "\n",
        "        optimizer = Adam(0.0002, 0.5)\n",
        "\n",
        "        # Build and compile the discriminator\n",
        "        self.discriminator = self.build_discriminator()\n",
        "        self.discriminator.compile(loss=['mse', 'categorical_crossentropy'],\n",
        "            loss_weights=[0.5, 0.5],\n",
        "            optimizer=optimizer,\n",
        "            metrics=['accuracy'])\n",
        "\n",
        "        # Build the generator\n",
        "        self.generator = self.build_generator()\n",
        "\n",
        "        # The generator takes noise as input and generates imgs\n",
        "        masked_img = Input(shape=self.img_shape)\n",
        "        gen_img = self.generator(masked_img)\n",
        "\n",
        "        # For the combined model we will only train the generator\n",
        "        self.discriminator.trainable = False\n",
        "\n",
        "        # The valid takes generated images as input and determines validity\n",
        "        valid, _ = self.discriminator(gen_img)\n",
        "\n",
        "        # The combined model  (stacked generator and discriminator)\n",
        "        # Trains the generator to fool the discriminator\n",
        "        self.combined = Model(masked_img , valid)\n",
        "        self.combined.compile(loss=['mse'],\n",
        "            optimizer=optimizer)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6OmPwlFVlb0e",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def build_generator(self):\n",
        "    \"\"\"U-Net Generator\"\"\"\n",
        "\n",
        "    def conv2d(layer_input, filters, f_size=4, bn=True):\n",
        "        \"\"\"Layers used during downsampling\"\"\"\n",
        "        d = Conv2D(filters, kernel_size=f_size, strides=2, padding='same')(layer_input)\n",
        "        d = LeakyReLU(alpha=0.2)(d)\n",
        "        if bn:\n",
        "            d = BatchNormalization(momentum=0.8)(d)\n",
        "        return d\n",
        "\n",
        "    def deconv2d(layer_input, skip_input, filters, f_size=4, dropout_rate=0):\n",
        "        \"\"\"Layers used during upsampling\"\"\"\n",
        "        u = UpSampling2D(size=2)(layer_input)\n",
        "        u = Conv2D(filters, kernel_size=f_size, strides=1, padding='same', activation='relu')(u)\n",
        "        if dropout_rate:\n",
        "            u = Dropout(dropout_rate)(u)\n",
        "        u = BatchNormalization(momentum=0.8)(u)\n",
        "        u = Concatenate()([u, skip_input])\n",
        "        return u\n",
        "\n",
        "    img = Input(shape=self.img_shape)\n",
        "\n",
        "    # Downsampling\n",
        "    d1 = conv2d(img, self.gf, bn=False)\n",
        "    d2 = conv2d(d1, self.gf*2)\n",
        "    d3 = conv2d(d2, self.gf*4)\n",
        "    d4 = conv2d(d3, self.gf*8)\n",
        "\n",
        "    # Upsampling\n",
        "    u1 = deconv2d(d4, d3, self.gf*4)\n",
        "    u2 = deconv2d(u1, d2, self.gf*2)\n",
        "    u3 = deconv2d(u2, d1, self.gf)\n",
        "\n",
        "    u4 = UpSampling2D(size=2)(u3)\n",
        "    output_img = Conv2D(self.channels, kernel_size=4, strides=1, padding='same', activation='tanh')(u4)\n",
        "\n",
        "    return Model(img, output_img)\n",
        "\n",
        "CCGAN.build_generator = build_generator\n",
        "del build_generator"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uuO1TvMWli_0",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "def build_discriminator(self):\n",
        "\n",
        "    img = Input(shape=self.img_shape)\n",
        "\n",
        "    model = Sequential()\n",
        "    model.add(Conv2D(64, kernel_size=4, strides=2, padding='same', input_shape=self.img_shape))\n",
        "    model.add(LeakyReLU(alpha=0.8))\n",
        "    model.add(Conv2D(128, kernel_size=4, strides=2, padding='same'))\n",
        "    model.add(LeakyReLU(alpha=0.2))\n",
        "    model.add(InstanceNormalization())\n",
        "    model.add(Conv2D(256, kernel_size=4, strides=2, padding='same'))\n",
        "    model.add(LeakyReLU(alpha=0.2))\n",
        "    model.add(InstanceNormalization())\n",
        "\n",
        "    model.summary()\n",
        "\n",
        "    img = Input(shape=self.img_shape)\n",
        "    features = model(img)\n",
        "\n",
        "    validity = Conv2D(1, kernel_size=4, strides=1, padding='same')(features)\n",
        "\n",
        "    label = Flatten()(features)\n",
        "    label = Dense(self.num_classes+1, activation=\"softmax\")(label)\n",
        "\n",
        "    return Model(img, [validity, label])\n",
        "\n",
        "CCGAN.build_discriminator = build_discriminator\n",
        "del build_discriminator"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9AfWpXdQrGq7",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "def mask_randomly(self, imgs):\n",
        "    y1 = np.random.randint(0, self.img_rows - self.mask_height, imgs.shape[0])\n",
        "    y2 = y1 + self.mask_height\n",
        "    x1 = np.random.randint(0, self.img_rows - self.mask_width, imgs.shape[0])\n",
        "    x2 = x1 + self.mask_width\n",
        "\n",
        "    masked_imgs = np.empty_like(imgs)\n",
        "    for i, img in enumerate(imgs):\n",
        "        masked_img = img.copy()\n",
        "        _y1, _y2, _x1, _x2 = y1[i], y2[i], x1[i], x2[i],\n",
        "        masked_img[_y1:_y2, _x1:_x2, :] = 0\n",
        "        masked_imgs[i] = masked_img\n",
        "\n",
        "    return masked_imgs\n",
        "\n",
        "CCGAN.mask_randomly = mask_randomly\n",
        "del mask_randomly"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zpZk_h36rLLD",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "def train(self, epochs, batch_size=128, sample_interval=50):\n",
        "\n",
        "    # Load the dataset\n",
        "    (X_train, y_train), (_, _) = mnist.load_data()\n",
        "\n",
        "    # Rescale MNIST to 32x32\n",
        "\n",
        "\n",
        "    X_train = np.array([  np.array(Image.fromarray(x).resize((self.img_rows, self.img_cols))) for x in X_train])\n",
        "\n",
        "    # Rescale -1 to 1\n",
        "    X_train = (X_train.astype(np.float32) - 127.5) / 127.5\n",
        "    X_train = np.expand_dims(X_train, axis=3)\n",
        "    y_train = y_train.reshape(-1, 1)\n",
        "\n",
        "    # Adversarial ground truths\n",
        "    valid = np.ones((batch_size, 4, 4, 1))\n",
        "    fake = np.zeros((batch_size, 4, 4, 1))\n",
        "\n",
        "    for epoch in range(epochs):\n",
        "\n",
        "        # ---------------------\n",
        "        #  Train Discriminator\n",
        "        # ---------------------\n",
        "\n",
        "        # Sample half batch of images\n",
        "        idx = np.random.randint(0, X_train.shape[0], batch_size)\n",
        "        imgs = X_train[idx]\n",
        "        labels = y_train[idx]\n",
        "\n",
        "        masked_imgs = self.mask_randomly(imgs)\n",
        "\n",
        "        # Generate a half batch of new images\n",
        "        gen_imgs = self.generator.predict(masked_imgs)\n",
        "\n",
        "        # One-hot encoding of labels\n",
        "        labels = to_categorical(labels, num_classes=self.num_classes+1)\n",
        "        fake_labels = to_categorical(np.full((batch_size, 1), self.num_classes), num_classes=self.num_classes+1)\n",
        "\n",
        "        # Train the discriminator\n",
        "        d_loss_real = self.discriminator.train_on_batch(imgs, [valid, labels])\n",
        "        d_loss_fake = self.discriminator.train_on_batch(gen_imgs, [fake, fake_labels])\n",
        "        d_loss = 0.5 * np.add(d_loss_real, d_loss_fake)\n",
        "\n",
        "        # ---------------------\n",
        "        #  Train Generator\n",
        "        # ---------------------\n",
        "\n",
        "        # Train the generator\n",
        "        g_loss = self.combined.train_on_batch(masked_imgs, valid)\n",
        "\n",
        "        # Plot the progress\n",
        "        print (\"%d [D loss: %f, op_acc: %.2f%%] [G loss: %f]\" % (epoch, d_loss[0], 100*d_loss[4], g_loss))\n",
        "\n",
        "        # If at save interval => save generated image samples\n",
        "        if epoch % sample_interval == 0:\n",
        "            # Select a random half batch of images\n",
        "            idx = np.random.randint(0, X_train.shape[0], 6)\n",
        "            imgs = X_train[idx]\n",
        "            self.sample_images(epoch, imgs)\n",
        "            self.save_model()\n",
        "\n",
        "CCGAN.train = train\n",
        "del train"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EokuVku-rMnX",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "def sample_images(self, epoch, imgs):\n",
        "    r, c = 3, 6\n",
        "\n",
        "    masked_imgs = self.mask_randomly(imgs)\n",
        "    gen_imgs = self.generator.predict(masked_imgs)\n",
        "\n",
        "    imgs = (imgs + 1.0) * 0.5\n",
        "    masked_imgs = (masked_imgs + 1.0) * 0.5\n",
        "    gen_imgs = (gen_imgs + 1.0) * 0.5\n",
        "\n",
        "    gen_imgs = np.where(gen_imgs < 0, 0, gen_imgs)\n",
        "\n",
        "    fig, axs = plt.subplots(r, c)\n",
        "    for i in range(c):\n",
        "        axs[0,i].imshow(imgs[i, :, :, 0], cmap='gray')\n",
        "        axs[0,i].axis('off')\n",
        "        axs[1,i].imshow(masked_imgs[i, :, :, 0], cmap='gray')\n",
        "        axs[1,i].axis('off')\n",
        "        axs[2,i].imshow(gen_imgs[i, :, :, 0], cmap='gray')\n",
        "        axs[2,i].axis('off')\n",
        "    fig.savefig(\"images/%d.png\" % epoch)\n",
        "    plt.close()\n",
        "\n",
        "CCGAN.sample_images = sample_images\n",
        "del sample_images"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mzv3_2OJrOIg",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "def save_model(self):\n",
        "\n",
        "    def save(model, model_name):\n",
        "        model_path = \"saved_model/%s.json\" % model_name\n",
        "        weights_path = \"saved_model/%s_weights.hdf5\" % model_name\n",
        "        options = {\"file_arch\": model_path,\n",
        "                    \"file_weight\": weights_path}\n",
        "        json_string = model.to_json()\n",
        "        open(options['file_arch'], 'w').write(json_string)\n",
        "        model.save_weights(options['file_weight'])\n",
        "\n",
        "    save(self.generator, \"ccgan_generator\")\n",
        "    save(self.discriminator, \"ccgan_discriminator\")\n",
        "\n",
        "CCGAN.save_model = save_model\n",
        "del save_model"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iS7-A8kirPG6",
        "colab_type": "code",
        "outputId": "4fa668fd-4c3d-4f32-ee21-0bbaa46966b8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 782
        }
      },
      "source": [
        "\n",
        "ccgan = CCGAN()\n",
        "ccgan.train(epochs=20000, batch_size=32, sample_interval=200)          \n"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_2\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "conv2d_13 (Conv2D)           (None, 16, 16, 64)        1088      \n",
            "_________________________________________________________________\n",
            "leaky_re_lu_8 (LeakyReLU)    (None, 16, 16, 64)        0         \n",
            "_________________________________________________________________\n",
            "conv2d_14 (Conv2D)           (None, 8, 8, 128)         131200    \n",
            "_________________________________________________________________\n",
            "leaky_re_lu_9 (LeakyReLU)    (None, 8, 8, 128)         0         \n",
            "_________________________________________________________________\n",
            "instance_normalization_3 (In (None, 8, 8, 128)         2         \n",
            "_________________________________________________________________\n",
            "conv2d_15 (Conv2D)           (None, 4, 4, 256)         524544    \n",
            "_________________________________________________________________\n",
            "leaky_re_lu_10 (LeakyReLU)   (None, 4, 4, 256)         0         \n",
            "_________________________________________________________________\n",
            "instance_normalization_4 (In (None, 4, 4, 256)         2         \n",
            "=================================================================\n",
            "Total params: 656,836\n",
            "Trainable params: 656,836\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/keras/engine/training.py:493: UserWarning: Discrepancy between trainable weights and collected trainable weights, did you set `model.trainable` without calling `model.compile` after ?\n",
            "  'Discrepancy between trainable weights and collected trainable'\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-10-73cd642edfa2>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mccgan\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mCCGAN\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mccgan\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m20000\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m32\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msample_interval\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m200\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-6-20b203fc9d17>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(self, epochs, batch_size, sample_interval)\u001b[0m\n\u001b[1;32m     40\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     41\u001b[0m         \u001b[0;31m# Train the discriminator\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 42\u001b[0;31m         \u001b[0md_loss_real\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdiscriminator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_on_batch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimgs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mvalid\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     43\u001b[0m         \u001b[0md_loss_fake\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdiscriminator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_on_batch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgen_imgs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mfake\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfake_labels\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     44\u001b[0m         \u001b[0md_loss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0.5\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0md_loss_real\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0md_loss_fake\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mtrain_on_batch\u001b[0;34m(self, x, y, sample_weight, class_weight)\u001b[0m\n\u001b[1;32m   1447\u001b[0m             \u001b[0mins\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mx\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0my\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0msample_weights\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1448\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_train_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1449\u001b[0;31m         \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mins\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1450\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0munpack_singleton\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1451\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   2977\u001b[0m                     \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_legacy_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2978\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2979\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2980\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2981\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mpy_any\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mis_tensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   2935\u001b[0m             \u001b[0mfetched\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_callable_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0marray_vals\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun_metadata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2936\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2937\u001b[0;31m             \u001b[0mfetched\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_callable_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0marray_vals\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2938\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mfetched\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2939\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/client/session.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1470\u001b[0m         ret = tf_session.TF_SessionRunCallable(self._session._session,\n\u001b[1;32m   1471\u001b[0m                                                \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_handle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1472\u001b[0;31m                                                run_metadata_ptr)\n\u001b[0m\u001b[1;32m   1473\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1474\u001b[0m           \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "p5efzlX83gTC",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 303
        },
        "outputId": "edddd19d-c0eb-4703-8259-35f1bb6887ca"
      },
      "source": [
        "!ls images/*\n",
        "img = plt.imread(\"images/800.png\")\n",
        "plt.imshow(img)"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "images/0.png  images/200.png  images/400.png  images/600.png  images/800.png\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.image.AxesImage at 0x7f11c4aac390>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 12
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAW4AAAD8CAYAAABXe05zAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nlyGGWxAEwWX8f72SjuQ+BxFHAAAAAElFTkSuQmCC\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    }
  ]
}